{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# coding=utf-8\n",
    "import sys, gc, ipaddress, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import chi2,skew,kurtosis,moment\n",
    "from functools import reduce\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, pairwise_distances\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from outlier_detection import MEllipticEnvelope\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleasing(m_df):\n",
    "    # data cleasing, feature engineering and save clean data into pickles\n",
    "\n",
    "    print('### Data Cleasing and Feature Engineering')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # [Protocol] - Discard ipv6-icmp and categorize\n",
    "    m_df = m_df[m_df.Proto != 'ipv6-icmp']\n",
    "    m_df['Proto'] = m_df['Proto'].fillna('-')\n",
    "    m_df['Proto'] = le.fit_transform(m_df['Proto'])\n",
    "\n",
    "    # [Label] - Categorize\n",
    "    anomalies = m_df.Label.str.contains('Botnet')\n",
    "    normal = np.invert(anomalies)\n",
    "    m_df.loc[anomalies, 'Label'] = np.uint8(1)\n",
    "    m_df.loc[normal, 'Label'] = np.uint8(0)\n",
    "    m_df['Label'] = pd.to_numeric(m_df['Label'])\n",
    "\n",
    "    # [Dport] - replace NaN with 0 port number\n",
    "    m_df['Dport'] = m_df['Dport'].fillna('0')\n",
    "    m_df['Dport'] = m_df['Dport'].apply(lambda x: int(x, 0))\n",
    "\n",
    "    # [sport] - replace NaN with 0 port number\n",
    "    try:\n",
    "        m_df['Sport'] = m_df['Sport'].fillna('0')\n",
    "        m_df['Sport'] = m_df['Sport'].str.replace('.*x+.*', '0')\n",
    "        m_df['Sport'] = m_df['Sport'].apply(lambda x: int(x, 0))\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "\n",
    "    # [sTos] - replace NaN with \"10\" and convert to int\n",
    "    m_df['sTos'] = m_df['sTos'].fillna('10')\n",
    "    m_df['sTos'] = m_df['sTos'].astype(int)\n",
    "\n",
    "    # [dTos] - replace NaN with \"10\" and convert to int\n",
    "    m_df['dTos'] = m_df['dTos'].fillna('10')\n",
    "    m_df['dTos'] = m_df['dTos'].astype(int)\n",
    "\n",
    "    # [State] - replace NaN with \"-\" and categorize\n",
    "    m_df['State'] = m_df['State'].fillna('-')\n",
    "    m_df['State'] = le.fit_transform(m_df['State'])\n",
    "\n",
    "    # [Dir] - replace NaN with \"-\" and categorize\n",
    "    m_df['Dir'] = m_df['Dir'].fillna('-')\n",
    "    m_df['Dir'] = le.fit_transform(m_df['Dir'])\n",
    "\n",
    "    # [SrcAddr] Extract subnet features and categorize\n",
    "    m_df['SrcAddr'] = m_df['SrcAddr'].fillna('0.0.0.0')\n",
    "\n",
    "    # [DstAddr] Extract subnet features\n",
    "    m_df['DstAddr'] = m_df['DstAddr'].fillna('0.0.0.0')\n",
    "\n",
    "    # [StartTime] - Parse to datatime, reindex based on StartTime, but first drop the ns off the time stamps\n",
    "    m_df['StartTime'] = m_df['StartTime'].apply(lambda x: x[:19])\n",
    "    m_df['StartTime'] = pd.to_datetime(m_df['StartTime'])\n",
    "\n",
    "    m_df = m_df.set_index('StartTime')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return m_df\n",
    "\n",
    "\n",
    "def classify_ip(ip):\n",
    "    \"\"\"\n",
    "    str ip - ip address string to attempt to classify. treat ipv6 addresses as N/A\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ip_addr = ipaddress.ip_address(ip)\n",
    "        if isinstance(ip_addr, ipaddress.IPv6Address):\n",
    "            return 'ipv6'\n",
    "        elif isinstance(ip_addr, ipaddress.IPv4Address):\n",
    "            # split on .\n",
    "            octs = ip_addr.exploded.split('.')\n",
    "            if 0 < int(octs[0]) < 127:\n",
    "                return 'A'\n",
    "            elif 127 < int(octs[0]) < 192:\n",
    "                return 'B'\n",
    "            elif 191 < int(octs[0]) < 224:\n",
    "                return 'C'\n",
    "            else:\n",
    "                return 'N/A'\n",
    "    except ValueError:\n",
    "        return 'N/A'\n",
    "\n",
    "\n",
    "def avg_duration(x):\n",
    "    return np.average(x)\n",
    "\n",
    "\n",
    "def n_dports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b > 1024 else a), x)\n",
    "\n",
    "\n",
    "n_dports_gt1024.__name__ = 'n_dports>1024'\n",
    "\n",
    "\n",
    "def n_dports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b < 1024 else a), x)\n",
    "\n",
    "\n",
    "n_dports_lt1024.__name__ = 'n_dports<1024'\n",
    "\n",
    "\n",
    "def n_sports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b > 1024 else a), x)\n",
    "\n",
    "\n",
    "n_sports_gt1024.__name__ = 'n_sports>1024'\n",
    "\n",
    "\n",
    "def n_sports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b < 1024 else a), x)\n",
    "\n",
    "\n",
    "n_sports_lt1024.__name__ = 'n_sports<1024'\n",
    "\n",
    "\n",
    "def label_atk_v_norm(x):\n",
    "    for l in x:\n",
    "        if l == 1: return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "label_atk_v_norm.__name__ = 'label'\n",
    "\n",
    "\n",
    "def background_flow_count(x):\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def normal_flow_count(x):\n",
    "    if x.size == 0: return 0\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_conn(x):\n",
    "    return x.size\n",
    "\n",
    "\n",
    "def n_tcp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 10: count += 1  # tcp == 10\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_udp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 11: count += 1  # udp == 11\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_icmp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 1: count += 1  # icmp == 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'B': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_ipv6(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'ipv6': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, y_predic):\n",
    "    m_f1 = f1_score(y_test, y_predic, average=\"binary\")\n",
    "    m_recall = recall_score(y_test, y_predic, average=\"binary\")\n",
    "    m_precision = precision_score(y_test, y_predic, average=\"binary\")\n",
    "    print('\\tF1 Score: ', m_f1, ', Recall: ', m_recall, ', Precision: ,', m_precision)\n",
    "\n",
    "\n",
    "def get_classification_report(y_test, y_predic):\n",
    "    m_f1 = f1_score(y_test, y_predic, average = \"binary\")\n",
    "    m_recall = recall_score(y_test, y_predic, average = \"binary\")\n",
    "    m_precision = precision_score(y_test, y_predic, average = \"binary\")\n",
    "    return m_f1, m_recall, m_precision\n",
    "\n",
    "\n",
    "def data_splitting(m_df, drop_feature):\n",
    "    # drop non discriminant features\n",
    "    m_df.drop(drop_feature, axis=1, inplace=True)\n",
    "\n",
    "    # split into normal and anomaly\n",
    "    df_l1 = m_df[m_df[\"Label\"] == 1]\n",
    "    df_l0 = m_df[m_df[\"Label\"] == 0]\n",
    "    gc.collect()\n",
    "\n",
    "    # Length and indexes\n",
    "    anom_len = len(df_l1)  # total number of anomalous flows\n",
    "    anom_train_end = anom_len // 2  # 50% of anomalous for training\n",
    "    anom_cv_start = anom_train_end + 1  # 50% of anomalous for testing\n",
    "    normal_len = len(df_l0)  # total number of normal flows\n",
    "    normal_train_end = (normal_len * 60) // 100  # 60% of normal for training\n",
    "    normal_cv_start = normal_train_end + 1  # 20% of normal for cross validation\n",
    "    normal_cv_end = (normal_len * 80) // 100  # 20% of normal for cross validation\n",
    "    normal_test_start = normal_cv_end + 1  # 20% of normal for testing\n",
    "\n",
    "    # anomalies split data\n",
    "    anom_cv_df = df_l1[:anom_train_end]  # 50% of anomalies59452\n",
    "    anom_test_df = df_l1[anom_cv_start:anom_len]  # 50% of anomalies\n",
    "    gc.collect()\n",
    "\n",
    "    # normal split data\n",
    "    m_normal_train_df = df_l0[:normal_train_end]  # 60% of normal\n",
    "    normal_cv_df = df_l0[normal_cv_start:normal_cv_end]  # 20% of normal\n",
    "    normal_test_df = df_l0[normal_test_start:normal_len]  # 20% of normal\n",
    "    gc.collect()\n",
    "\n",
    "    # CV and test data. train data is normal_train_df\n",
    "    m_cv_df = pd.concat([normal_cv_df, anom_cv_df], axis=0)\n",
    "    m_test_df = pd.concat([normal_test_df, anom_test_df], axis=0)\n",
    "    gc.collect()\n",
    "\n",
    "    # Sort data by index\n",
    "    m_normal_train_df = m_normal_train_df.sort_index()\n",
    "    m_cv_df = m_cv_df.sort_index()\n",
    "    m_test_df = m_test_df.sort_index()\n",
    "    gc.collect()\n",
    "\n",
    "    # save labels and drop labels from data\n",
    "    m_cv_label = m_cv_df[\"Label\"]\n",
    "    m_test_label = m_test_df[\"Label\"]\n",
    "    m_normal_train_df = m_normal_train_df.drop(labels=[\"Label\"], axis=1)\n",
    "    m_cv_df = m_cv_df.drop(labels=[\"Label\"], axis=1)\n",
    "    m_test_df = m_test_df.drop(labels=[\"Label\"], axis=1)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return m_normal_train_df, m_cv_df, m_test_df, m_cv_label, m_test_label\n",
    "\n",
    "\n",
    "def getBestBySemiSupervCV(t_normal_df, t_cv_df, t_cv_label):\n",
    "\n",
    "    m_cv_label = t_cv_label.astype(np.int8)\n",
    "\n",
    "    # initialize\n",
    "    m_best_model = MEllipticEnvelope()\n",
    "    m_best_contamination = -1\n",
    "    m_best_f1 = -1\n",
    "    m_best_precision = -1\n",
    "    m_best_recall = -1\n",
    "\n",
    "    # configure GridSearchCV\n",
    "    for m_contamination in np.linspace(0.01, 0.2, 2):\n",
    "        m_ell_model = MEllipticEnvelope(contamination = m_contamination)\n",
    "        m_ell_model.fit(t_normal_df)\n",
    "        m_pred = m_ell_model.predict(t_cv_df)\n",
    "        m_pred[m_pred == 1] = 0\n",
    "        m_pred[m_pred == -1] = 1\n",
    "\n",
    "        m_f1 = f1_score(m_cv_label, m_pred, average=\"binary\")\n",
    "        m_recall = recall_score(m_cv_label, m_pred, average=\"binary\")\n",
    "        m_precision = precision_score(m_cv_label, m_pred, average=\"binary\")\n",
    "\n",
    "        if m_f1 > m_best_f1:\n",
    "            m_best_model = m_ell_model\n",
    "            m_best_contamination = m_contamination\n",
    "            m_best_f1 = m_f1\n",
    "            m_best_precision = m_precision\n",
    "            m_best_recall = m_recall\n",
    "            print('###[EllipticEnvelope] Cross-Validation. Contamination:', m_contamination,',F1:', m_f1, \n",
    "              ', Recall:', m_recall, ', Precision:', m_precision)\n",
    "\n",
    "    return m_best_model, m_best_contamination, m_best_f1, m_best_precision, m_best_recall\n",
    "\n",
    "\n",
    "def getBestBySemiSupervKurtosisCV(t_normal_df, t_cv_df, t_cv_label):\n",
    "\n",
    "    m_cv_label = t_cv_label.astype(np.int8)\n",
    "\n",
    "    # initialize\n",
    "    m_best_model = MEllipticEnvelope()\n",
    "    m_best_contamination = -1\n",
    "    m_best_f1 = -1\n",
    "    m_best_precision = -1\n",
    "    m_best_recall = -1\n",
    "\n",
    "    # configure GridSearchCV\n",
    "    for m_contamination in np.linspace(0.01, 0.2, 20):\n",
    "        m_ell_model = MEllipticEnvelope(contamination = m_contamination)\n",
    "        m_ell_model.fit(t_normal_df)\n",
    "        m_pred = m_ell_model.kurtosis_prediction(t_cv_df)\n",
    "\n",
    "        m_f1 = f1_score(m_cv_label, m_pred, average=\"binary\")\n",
    "        m_recall = recall_score(m_cv_label, m_pred, average=\"binary\")\n",
    "        m_precision = precision_score(m_cv_label, m_pred, average=\"binary\")\n",
    "\n",
    "        if m_f1 > m_best_f1:\n",
    "            m_best_model = m_ell_model\n",
    "            m_best_contamination = m_contamination\n",
    "            m_best_f1 = m_f1\n",
    "            m_best_precision = m_precision\n",
    "            m_best_recall = m_recall\n",
    "            print('###[EllipticEnvelope] Cross-Validation. Contamination:', m_contamination,',F1:', m_f1, \n",
    "              ', Recall:', m_recall, ', Precision:', m_precision)\n",
    "\n",
    "    return m_best_model, m_best_contamination, m_best_f1, m_best_precision, m_best_recall\n",
    "\n",
    "\n",
    "def getBestBySupervCV(t_normal_df, t_cv_df, t_cv_label):\n",
    "    \n",
    "    m_normal_train_df = t_normal_df.copy()\n",
    "    m_cv_df = t_cv_df.copy()\n",
    "    \n",
    "    m_normal_train_df['Label'] = 0\n",
    "    m_cv_df['Label'] = t_cv_label.astype(np.int8)\n",
    "    m_train_df = m_normal_train_df.append(m_cv_df)\n",
    "    m_train_df = m_train_df.sort_index()\n",
    "    gc.collect()\n",
    "\n",
    "    # Length and indexes\n",
    "    m_total_len = len(m_train_df)\n",
    "    m_train_end = (m_total_len * 80) // 100\n",
    "    m_test_start = m_train_end + 1\n",
    "\n",
    "    m_train = m_train_df[:m_train_end]\n",
    "    m_test = m_train_df[m_test_start:]\n",
    "\n",
    "    m_test_label = m_test['Label']\n",
    "    m_train = m_train.drop(labels=[\"Label\"], axis=1)\n",
    "    m_test = m_test.drop(labels=[\"Label\"], axis=1)\n",
    "\n",
    "    # initialize\n",
    "    m_best_model = MEllipticEnvelope()\n",
    "    m_best_contamination = -1\n",
    "    m_best_f1 = -1\n",
    "    m_best_precision = -1\n",
    "    m_best_recall = -1\n",
    "\n",
    "    # configure GridSearchCV\n",
    "    for m_contamination in np.linspace(0.01, 0.2, 20):  \n",
    "        m_ell_model = MEllipticEnvelope(contamination = m_contamination)\n",
    "        m_ell_model.fit(m_train)\n",
    "        m_pred = m_ell_model.predict(m_test)\n",
    "        m_pred[m_pred == 1] = 0\n",
    "        m_pred[m_pred == -1] = 1\n",
    "\n",
    "        m_f1 = f1_score(m_test_label, m_pred, average=\"binary\")\n",
    "        m_recall = recall_score(m_test_label, m_pred, average=\"binary\")\n",
    "        m_precision = precision_score(m_test_label, m_pred, average=\"binary\")\n",
    "\n",
    "        if m_f1 > m_best_f1:\n",
    "            m_best_model = m_ell_model\n",
    "            m_best_contamination = m_contamination\n",
    "            m_best_f1 = m_f1\n",
    "            m_best_precision = m_precision\n",
    "            m_best_recall = m_recall\n",
    "            print('###[EllipticEnvelope] Cross-Validation. Contamination:', m_contamination,',F1:', m_f1, \n",
    "              ', Recall:', m_recall, ', Precision:', m_precision)\n",
    "    return m_best_model, m_best_contamination, m_best_f1, m_best_precision, m_best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere_botnet_2011/ctu_13/pkl/capture20110818.binetflow\n"
     ]
    }
   ],
   "source": [
    "column_types = {\n",
    "    'StartTime': 'str',\n",
    "    'Dur': 'float32',\n",
    "    'Proto': 'str',\n",
    "    'SrcAddr': 'str',\n",
    "    'Sport': 'str',\n",
    "    'Dir': 'str',\n",
    "    'DstAddr': 'str',\n",
    "    'Dport': 'str',\n",
    "    'State': 'str',\n",
    "    'sTos': 'float16',\n",
    "    'dTos': 'float16',\n",
    "    'TotPkts': 'uint32',\n",
    "    'TotBytes': 'uint32',\n",
    "    'SrcBytes': 'uint32',\n",
    "    'Label': 'uint8'}\n",
    "\n",
    "# feature selection\n",
    "drop_features = {\n",
    "    'drop_features01': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'TotBytes', 'Proto'],\n",
    "    'drop_features02': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'TotBytes'],\n",
    "    'drop_features03': ['SrcAddr', 'DstAddr', 'sTo's', 'Sport', 'SrcBytes', 'Proto'],\n",
    "    'drop_features04': ['SrcAddr', 'DstAddr', 'sTos', 'Proto']\n",
    "}\n",
    "\n",
    "features_key = 'drop_features04'\n",
    "\n",
    "pkl_file_path = '/media/thiago/ubuntu/datasets/network/stratosphere_botnet_2011/ctu_13/pkl/capture20110818.binetflow'\n",
    "print(\"## Sample File: \", pkl_file_path)\n",
    "df = pd.read_pickle(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "norm_train_df, cv_df, test_df, cv_label, test_label = data_splitting(df, drop_features[features_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross-Validation and model selection\n",
    "# ell_model, best_contamination, best_f1, best_precision, best_recall = getBestBySemiSupervCV(norm_train_df, cv_df, cv_label)\n",
    "# print('###[EllipticEnvelope][', features_key, '] Cross-Validation. Contamination:',best_contamination,',F1:', best_f1, ', Recall:', best_recall, ', Precision:', best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation and model selection\n",
    "ell_model, best_contamination, best_f1, best_precision, best_recall = getBestBySemiSupervKurtosisCV(norm_train_df, cv_df, cv_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Cross-Validation. Contamination:',best_contamination,',F1:', best_f1, ', Recall:', best_recall, ', Precision:', best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Cross-Validation and model selection\n",
    "# ell_model, best_contamination, best_f1, best_precision, best_recall = getBestBySupervCV(norm_train_df, cv_df, cv_label)\n",
    "# print('###[EllipticEnvelope][', features_key, '] Cross-Validation. Contamination:',best_contamination,',F1:', best_f1, ', Recall:', best_recall, ', Precision:', best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test EllipticEnvelope\n",
    "test_label = test_label.astype(np.int8)\n",
    "pred_test_label = ell_model.predict(test_df)\n",
    "pred_test_label[pred_test_label == 1] = 0\n",
    "pred_test_label[pred_test_label == -1] = 1\n",
    "\n",
    "# print results\n",
    "unique, counts = np.unique(test_label, return_counts=True)\n",
    "print('Test Labels', dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "print('Predicted Labels', dict(zip(unique, counts)))\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction using skew1\n",
    "pred_test_label = ell_model.skewness_prediction(test_df)\n",
    "\n",
    "# print results\n",
    "unique, counts = np.unique(test_label, return_counts=True)\n",
    "print('Test Labels', dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "print('Predicted Labels', dict(zip(unique, counts)))\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[skew1][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "X = pd.DataFrame()\n",
    "X['RawDist'] = raw_dist\n",
    "X['RobustDist'] = ell_model.prediction_dist_\n",
    "X['Label'] = test_label\n",
    "inlier = X[X[\"Label\"] == 0]\n",
    "outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# Plot scatter of inliers and outliers\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.title(\"skew1 distances\")\n",
    "plt.xlabel(\"RawDist\")\n",
    "plt.ylabel(\"RobustDist\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the scores for each point\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RawDist Inliers')\n",
    "ax1.boxplot(inlier['RawDist'])\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RawDist Outliers')\n",
    "ax1.boxplot(outlier['RawDist'])\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RobustDist Inliers')\n",
    "ax1.boxplot(inlier['RobustDist'])\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RobustDist Outliers')\n",
    "ax1.boxplot(outlier['RobustDist'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using skew2\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_skew2 = test_df - skew(test_df, axis=0, bias=False)\n",
    "# mahal_dist = pairwise_distances(test_df_skew2, ell_model.raw_skew2_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_skew2),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.23)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the skew2_dist_\n",
    "# pred_test_label = np.full(test_df_skew2.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist <= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[skew2][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"skew2 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using kurt1\n",
    "pred_test_label = ell_model.kurtosis_prediction(test_df)\n",
    "\n",
    "# print results\n",
    "unique, counts = np.unique(test_label, return_counts=True)\n",
    "print('Test Labels', dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "print('Predicted Labels', dict(zip(unique, counts)))\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[kurt1][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "X = pd.DataFrame()\n",
    "X['RawDist'] = raw_dist\n",
    "X['RobustDist'] = ell_model.prediction_dist_\n",
    "X['Label'] = test_label\n",
    "inlier = X[X[\"Label\"] == 0]\n",
    "outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# Plot scatter of inliers and outliers\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.title(\"moment6 distances\")\n",
    "plt.xlabel(\"RawDist\")\n",
    "plt.ylabel(\"RobustDist\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the scores for each point\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RawDist Inliers')\n",
    "ax1.boxplot(inlier['RawDist'])\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RawDist Outliers')\n",
    "ax1.boxplot(outlier['RawDist'])\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RobustDist Inliers')\n",
    "ax1.boxplot(inlier['RobustDist'])\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('RobustDist Outliers')\n",
    "ax1.boxplot(outlier['RobustDist'])\n",
    "plt.show()\n",
    "\n",
    "unique, counts = np.unique(X['RobustDist'], return_counts=True)\n",
    "print('Predicted Labels', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using kurt2\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_kurt2 = test_df - kurtosis(test_df, axis=0, fisher=False, bias=True)\n",
    "# mahal_dist = pairwise_distances(test_df_kurt2, ell_model.raw_kurt2_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_kurt2),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.18)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the kurt2_dist_\n",
    "# pred_test_label = np.full(test_df_kurt2.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist <= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[kurt2][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"moment6 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using moment2\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_moment2 = test_df -moment(test_df, moment=2, axis=0)\n",
    "# mahal_dist = pairwise_distances(test_df_moment2, ell_model.raw_moment2_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_moment2),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.69)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the moment2_dist_\n",
    "# pred_test_label = np.full(test_df_moment2.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist >= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[moment2][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"moment6 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using moment3\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_moment3 = test_df -moment(test_df, moment=3, axis=0)\n",
    "# mahal_dist = pairwise_distances(test_df_moment3, ell_model.raw_moment3_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_moment3),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.95)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the moment3_dist_\n",
    "# pred_test_label = np.full(test_df_moment3.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist <= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[moment3][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"moment3 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using moment4\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_moment4 = test_df -moment(test_df, moment=4, axis=0)\n",
    "# mahal_dist = pairwise_distances(test_df_moment4, ell_model.raw_moment4_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_moment4),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.99)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the moment4_dist_\n",
    "# pred_test_label = np.full(test_df_moment4.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist >= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[moment4][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"moment4 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using moment5\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_moment5 = test_df -moment(test_df, moment=5, axis=0)\n",
    "# mahal_dist = pairwise_distances(test_df_moment5, ell_model.raw_moment5_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_moment5),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.99)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the moment5_dist_\n",
    "# pred_test_label = np.full(test_df_moment5.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist >= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[moment5][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"moment5 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction using moment6\n",
    "# inv_cov = linalg.pinvh(ell_model.covariance_)\n",
    "# test_df_moment6 = test_df -moment(test_df, moment=6, axis=0)\n",
    "# mahal_dist = pairwise_distances(test_df_moment6, ell_model.raw_moment6_[np.newaxis, :], metric='mahalanobis', VI=inv_cov)\n",
    "# mahal_dist = np.reshape(mahal_dist, (len(test_df_moment6),)) ** 2\n",
    "# mahal_dist = -mahal_dist\n",
    "# contamination_threshold = np.percentile(mahal_dist, 100. * 0.99)# manual contamination testing. here we modify the dec_fuction to use the current mahal_dist intead of the moment6_dist_\n",
    "# pred_test_label = np.full(test_df_moment6.shape[0], 0, dtype=int)\n",
    "# pred_test_label[mahal_dist >= contamination_threshold] = 1\n",
    "\n",
    "# # print results\n",
    "# unique, counts = np.unique(test_label, return_counts=True)\n",
    "# print('Test Labels', dict(zip(unique, counts)))\n",
    "# unique, counts = np.unique(pred_test_label, return_counts=True)\n",
    "# print('Predicted Labels', dict(zip(unique, counts)))\n",
    "# f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "# print('###[moment6][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dist = EmpiricalCovariance().fit(norm_train_df).mahalanobis(test_df)\n",
    "# X = pd.DataFrame()\n",
    "# X['RawDist'] = raw_dist\n",
    "# X['RobustDist'] = mahal_dist\n",
    "# X['Label'] = test_label\n",
    "# inlier = X[X[\"Label\"] == 0]\n",
    "# outlier = X[X[\"Label\"] == 1]\n",
    "\n",
    "# # Plot scatter of inliers and outliers\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(inlier['RawDist'], inlier['RobustDist'], color='black', label='inliers', alpha=0.07)\n",
    "# ax.scatter(outlier['RawDist'], outlier['RobustDist'], color='red', label='outliers', alpha=0.07)\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.title(\"moment6 distances\")\n",
    "# plt.xlabel(\"RawDist\")\n",
    "# plt.ylabel(\"RobustDist\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the scores for each point\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Inliers')\n",
    "# ax1.boxplot(inlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RawDist Outliers')\n",
    "# ax1.boxplot(outlier['RawDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Inliers')\n",
    "# ax1.boxplot(inlier['RobustDist'])\n",
    "# plt.show()\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('RobustDist Outliers')\n",
    "# ax1.boxplot(outlier['RobustDist'])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# -*- coding: utf-8 -*-
"""m-rpca

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uhAspwVSAdPrI5uwh7j3LSpAikuZylp-
"""

from __future__ import division
from __future__ import print_function

import os
import sys
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.font_manager
from scipy.stats import weibull_min
from numpy import percentile
# Import all models
from pyod.models.abod import ABOD
from pyod.models.cblof import CBLOF
from pyod.models.feature_bagging import FeatureBagging
from pyod.models.hbos import HBOS
from pyod.models.iforest import IForest
from pyod.models.knn import KNN
from pyod.models.lof import LOF
from pyod.models.loci import LOCI
from pyod.models.mcd import MCD
from pyod.models.ocsvm import OCSVM
from pyod.models.pca import PCA
from pyod.models.sos import SOS
from pyod.models.lscp import LSCP

import pandas as pd
from scipy import linalg
from scipy.stats import skew, kurtosis
from sklearn.metrics import pairwise_distances, f1_score
from tensorly.decomposition.robust_decomposition import robust_pca

from scipy.stats import skewnorm

# temporary solution for relative imports in case pyod is not installed
# if pyod is installed, no need to use the following line
sys.path.append(
    os.path.abspath(os.path.join(os.path.dirname("__file__"), '..')))


def fit_m_rpca(data, m_reg_J=1):
    """
    Robust PCA based estimation of mean, covariance, skewness and kurtosis.

    :param data: MxN matrix with M observations and N features, where M>N
    :param m_reg_J: regularization. Default value is 1
    :return:
        L: array-like, shape (m_obserations, n_features,)
            Robust data

        rob_mean:
        rob_cov:
        rob_dist:
        rob_precision:
        rob_skew:
        rob_skew_dist:
        rob_kurt:
        rob_kurt_dist:
    """

    L, S = robust_pca(data, reg_J=m_reg_J)

    rob_mean = L.mean(axis=0)
    rob_cov = pd.DataFrame(L).cov()
    rob_precision = linalg.pinvh(rob_cov)
    rob_dist = (np.dot(L, rob_precision) * L).sum(axis=1)

    rob_skew = skew(L, axis=0, bias=True)
    rob_skew_dist = (np.dot(L - rob_skew, rob_precision) * (L - rob_skew)).sum(axis=1)

    rob_kurt = kurtosis(L, axis=0, fisher=True, bias=True)
    rob_kurt_dist = (np.dot(L - rob_kurt, rob_precision) * (L - rob_kurt)).sum(axis=1)

    return L, rob_mean, rob_cov, rob_dist, rob_precision, rob_skew, rob_skew_dist, rob_kurt, rob_kurt_dist


def cv_location_contamination(cv_df, cv_labels, location, precision):
    """

    :param cv_df: cross-validation data frame
    :param cv_labels: labels to evaluate prediction performance by contamination
    :param location: mean vector
    :param precision: inverse of covariance matrix
    :return: For all tested contamination rates, returns the rate in which the best F1-score were achieved.
    """

    contamination = round(0.00, 2)
    contamination_prediction_list = []
    labels = np.array(cv_labels)

    for i in range(40):
        contamination += 0.01
        contamination = round(contamination, 2)
        pred_label = predict_by_location_contamination(cv_df, location, precision, contamination)
        contamination_prediction_list.append((contamination, f1_score(labels, pred_label, average="binary")))

    contamination_prediction_list.sort(key=lambda tup: tup[1], reverse=True)
    contamination_best_f1 = contamination_prediction_list[0][0]

    return contamination_best_f1


def cv_location_threshold(cv_df, cv_labels, location, precision, dist):
    """

    :param cv_df: cross-validation data frame
    :param cv_labels: labels to evaluate prediction performance by contamination
    :param location:
    :param precision:
    :return: For all tested contamination rates, returns the rate in which the best F1-score were achieved.
    """

    threshold_prediction_list = []
    labels = np.array(cv_labels)
    min_dist = min(dist)
    max_dist = max(dist)

    for m_threshold in np.linspace(min_dist, max_dist, 40):
        pred_label = predict_by_location_threshold(cv_df, location, precision, m_threshold)
        threshold_prediction_list.append((m_threshold, f1_score(labels, pred_label, average="binary")))

    threshold_prediction_list.sort(key=lambda tup: tup[1], reverse=True)
    best_threshold = threshold_prediction_list[0][0]

    return best_threshold


def cv_skewness_contamination(cv_df, cv_labels, skewness, precision):
    """

    :param cv_df: cross-validation data frame
    :param cv_labels: labels to evaluate prediction performance by contamination
    :param skewness:
    :param precision:
    :return: For all tested contamination rates, returns the rate in which the best F1-score were achieved.
    """

    contamination = round(0.00, 2)
    contamination_prediction_list = []
    actual_anomalies = np.array(cv_labels)
    for i in range(40):
        contamination += 0.01
        contamination = round(contamination, 2)
        pred_label = predict_by_skewness_contamination(cv_df, precision, skewness, contamination)
        contamination_prediction_list.append((contamination, f1_score(actual_anomalies, pred_label, average="binary")))

    contamination_prediction_list.sort(key=lambda tup: tup[1], reverse=True)
    best_contamination = contamination_prediction_list[0][0]

    return best_contamination


def cv_skewness_threshold(cv_df, cv_labels, skewness, precision, skew_dist):
    """

    :param cv_df:
    :param cv_labels: labels to evaluate prediction performance by contamination
    :param skewness:
    :param precision:
    :param skew_dist:
    :return:
    """

    threshold_prediction_list = []
    actual_anomalies = np.array(cv_labels)
    min_dist = min(skew_dist)
    max_dist = max(skew_dist)

    for m_threshold in np.linspace(min_dist, max_dist, 40):
        pred_label = predict_by_skewness_threshold(cv_df, precision, skewness, m_threshold)
        threshold_prediction_list.append((m_threshold, f1_score(actual_anomalies, pred_label, average="binary")))

    threshold_prediction_list.sort(key=lambda tup: tup[1], reverse=True)
    best_threshold = threshold_prediction_list[0][0]

    return best_threshold


def cv_kurtosis_contamination(cv_df, cv_labels, m_kurtosis, precision):
    """

    :param df: cross-validation data frame
    :param location:
    :param precision:
    :return: For all tested contamination rates, returns the rate in which the best F1-score were achieved.
    """

    contamination = round(0.00, 2)
    contamination_prediction_list = []
    actual_anomalies = np.array(cv_labels)
    for i in range(40):
        contamination += 0.01
        contamination = round(contamination, 2)
        pred_label = predict_by_kurtosis_contamination(cv_df, precision, m_kurtosis, contamination)
        contamination_prediction_list.append((contamination, f1_score(actual_anomalies, pred_label, average="binary")))

    contamination_prediction_list.sort(key=lambda tup: tup[1], reverse=True)
    best_contamination = contamination_prediction_list[0][0]

    return best_contamination


def cv_kurtosis_threshold(cv_df, cv_labels, kurtosis, precision, kurt_dist):
    """

    :param cv_df:
    :param cv_labels: labels to evaluate prediction performance by contamination
    :param kurtosis:
    :param precision:
    :param kurt_dist:
    :return:
    """

    threshold_prediction_list = []
    actual_anomalies = np.array(cv_labels)
    min_dist = min(kurt_dist)
    max_dist = max(kurt_dist)

    for m_threshold in np.linspace(min_dist, max_dist, 40):
        pred_label = predict_by_kurtosis_threshold(cv_df, precision, kurtosis, m_threshold)
        threshold_prediction_list.append((m_threshold, f1_score(actual_anomalies, pred_label, average="binary")))

    threshold_prediction_list.sort(key=lambda tup: tup[1], reverse=True)
    best_threshold = threshold_prediction_list[0][0]

    return best_threshold


def md_rpca_prediction(test_df, location, precision, contamination):
    """

    :param test_df:
    :param location:
    :param precision:
    :param contamination:
    :return:
    """

    pred_label = np.full(test_df.shape[0], 0, dtype=int)
    if contamination is not None:
        # malhalanobis distance
        mahal_dist = pairwise_distances(test_df, location[np.newaxis, :], metric='mahalanobis', VI=precision)
        mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2  # MD squared
        # detect outliers
        contamination_threshold = np.percentile(mahal_dist, 100. * (1. - contamination))
        pred_label[mahal_dist > contamination_threshold] = 1
    else:
        raise NotImplementedError("You must provide a contamination rate.")

    return pred_label


def predict_by_location_centered_contamination(X, location, precision, contamination):
    """

    :param X:
    :param location:
    :param precision:
    :param contamination:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)
    if contamination is not None:
        # malhalanobis distance
        X = X - location
        mahal_dist = pairwise_distances(X, location[np.newaxis, :], metric='mahalanobis', VI=precision)
        mahal_dist = np.reshape(mahal_dist, (len(X),)) ** 2  # MD squared
        # detect outliers
        contamination_threshold = np.percentile(mahal_dist, 100. * (1. - contamination))
        pred_label[mahal_dist > contamination_threshold] = 1
    else:
        raise NotImplementedError("You must provide a contamination rate.")

    return pred_label


def predict_by_location_threshold(X, location, precision, threshold):
    """

    :param X:
    :param location:
    :param precision:
    :param threshold:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X, location[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X),)) ** 2  # MD squared
    # detect outliers
    pred_label[mahal_dist > threshold] = 1

    return pred_label


def sd_rpca_prediction(X, skewness, precision, contamination):
    """

    :param X:
    :param precision:
    :param skewness:
    :param contamination:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X, skewness[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X),)) ** 2  # MD squared
    pred_skew_dist = -mahal_dist

    # detect outliers
    contamination_threshold = np.percentile(pred_skew_dist, 100. * contamination)
    pred_label[pred_skew_dist <= contamination_threshold] = 1

    return pred_label


def predict_by_skewness_centered_contamination(X, precision, skewness, contamination):
    """

    :param X:
    :param precision:
    :param skewness:
    :param contamination:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # skewness of the data
    X_skew = X - skew(X, axis=0, bias=True)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X_skew, skewness[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X_skew),)) ** 2  # MD squared
    pred_skew_dist = -mahal_dist

    # detect outliers
    contamination_threshold = np.percentile(pred_skew_dist, 100. * contamination)
    pred_label[pred_skew_dist <= contamination_threshold] = 1

    return pred_label


def predict_by_skewness_threshold(X, precision, skewness, threshold):
    """

    :param X:
    :param precision:
    :param skewness:
    :param threshold:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X, skewness[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X),)) ** 2  # MD squared
    pred_skew_dist = -mahal_dist

    # detect outliers
    pred_label[pred_skew_dist <= threshold] = 1

    return pred_label


def predict_by_skewness_centered_threshold(X, precision, skewness, threshold):
    """

    :param X:
    :param precision:
    :param skewness:
    :param threshold:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # skewness of the data
    X_skew = X - skew(X, axis=0, bias=True)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X_skew, skewness[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X_skew),)) ** 2  # MD squared
    pred_skew_dist = -mahal_dist

    # detect outliers
    pred_label[pred_skew_dist <= threshold] = 1

    return pred_label


def kd_rpca_prediction(X, m_kurtosis, precision, contamination):
    """

    :param X:
    :param precision:
    :param m_kurtosis	:
    :param contamination:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X, m_kurtosis[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X),)) ** 2  # MD squared
    pred_kurt_dist = -mahal_dist

    # detect outliers
    contamination_threshold = np.percentile(pred_kurt_dist, 100. * contamination)
    pred_label[pred_kurt_dist <= contamination_threshold] = 1

    return pred_label


def predict_by_kurtosis_centered_contamination(X, precision, m_kurtosis, contamination):
    """

    :param X:
    :param precision:
    :param m_kurtosis	:
    :param contamination:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # m_kurtosis	 of the data
    X_kurt = X - kurtosis(X, axis=0, bias=True)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X_kurt, m_kurtosis[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X_kurt),)) ** 2  # MD squared
    pred_kurt_dist = -mahal_dist

    # detect outliers
    contamination_threshold = np.percentile(pred_kurt_dist, 100. * contamination)
    pred_label[pred_kurt_dist <= contamination_threshold] = 1

    return pred_label


def predict_by_kurtosis_threshold(X, precision, m_kurtosis, threshold):
    """

    :param X:
    :param precision:
    :param m_kurtosis	:
    :param threshold:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X, m_kurtosis[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X),)) ** 2  # MD squared
    pred_kurt_dist = -mahal_dist

    # detect outliers
    pred_label[pred_kurt_dist <= threshold] = 1

    return pred_label


def predict_by_kurtosis_centered_threshold(X, precision, m_kurtosis, threshold):
    """

    :param X:
    :param precision:
    :param m_kurtosis	:
    :param threshold:
    :return:
    """

    pred_label = np.full(X.shape[0], 0, dtype=int)

    # m_kurtosis	 of the data
    X_kurt = X - kurtosis(X, axis=0, bias=True)

    # malhalanobis distance
    mahal_dist = pairwise_distances(X_kurt, m_kurtosis[np.newaxis, :], metric='mahalanobis', VI=precision)
    mahal_dist = np.reshape(mahal_dist, (len(X_kurt),)) ** 2  # MD squared
    pred_kurt_dist = -mahal_dist

    # detect outliers
    pred_label[pred_kurt_dist <= threshold] = 1

    return pred_label


# Define the number of inliers and outliers
n_samples = 2400
# outliers_fraction = 0.33
# outliers_fraction = 0.25
outliers_fraction = 0.10

result_path = 'output/simulation/'
data_path = 'data/simulation/'

# Initialize the data
n_inliers = int((1. - outliers_fraction) * n_samples)
n_outliers = int(n_samples - n_inliers)
ground_truth = np.zeros(n_samples, dtype=int)
ground_truth[-n_outliers:] = 1  # put outliers into the end

print('n_samples:', n_samples)
print('n_inliers:', n_inliers)
print('n_outliers:', n_outliers)
print('ground_truth:', ground_truth.shape)

# Data generation
# Gaussian
np.random.seed(11)
X1 = 0.3 * np.random.randn(n_inliers, 2)
X2 = 0.3 * np.random.randn(n_inliers, 2)
Xgaussian = np.r_[X1, X2]
Xgaussian_t = Xgaussian[:n_inliers]
Xgaussian = Xgaussian[n_inliers:]

# Append uniform outliers
Cuniform = np.random.uniform(low=-6, high=6, size=(n_outliers, 2))
Xgu = np.r_[Xgaussian, Cuniform]

Ctuniform = np.random.uniform(low=-6, high=6, size=(n_outliers, 2))
Xgaussian_tc = np.r_[Xgaussian_t, Ctuniform]

sns.distplot(Xgaussian[:, 0], color="blue", label="Gaussian")
sns.distplot(Xgaussian[:, 1], color="red", label="Gaussian")
plt.legend()
# plt.savefig("%sXgaussian.png" % result_path)
plt.show()
plt.close()

print('Xgaussian_t:', Xgaussian_t.shape)
sns.distplot(Xgaussian_t[:, 0], color="blue", label="Gaussian")
sns.distplot(Xgaussian_t[:, 1], color="red", label="Gaussian")
plt.legend()
# plt.savefig("%sXgaussian_t.png" % result_path)
plt.show()
plt.close()

# Append outliers
print('Cuniform:', Cuniform.shape)
sns.distplot(Cuniform[:, 0], color="blue", label="Uniform")
plt.legend()
# plt.savefig("%sCuniform.png" % result_path)
plt.show()
plt.close()

print('Xgu:', Xgu.shape)
sns.distplot(Xgu[:, 0], color="blue", label="Gaussian + Uniform")
plt.legend()
# plt.savefig("%sXgu.png" % result_path)
plt.show()
plt.legend()
plt.close()

sns.distplot(Xgaussian[:, 0], color="blue", label="Gaussian")
sns.distplot(Cuniform[:, 0], color="red", label="Uniform")
plt.legend()
# plt.savefig("%sXgu2.png" % result_path)
plt.show()
plt.close()

print('### Gaussian contaminated by Uniform')
# initialize a set of detectors for LSCP
detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),
                 LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),
                 LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),
                 LOF(n_neighbors=50)]

# Show the statics of the data
print('Number of inliers: %i' % n_inliers)
print('Number of outliers: %i' % n_outliers)
print('Contamination: %6.2f' % outliers_fraction)

random_state = np.random.RandomState(42)

# Define nine outlier detection tools to be compared
classifiers = {
    #     'Angle-based Outlier Detector (ABOD)': ABOD(contamination=outliers_fraction),
    'Cluster-based Local Outlier Factor (CBLOF)': CBLOF(contamination=outliers_fraction, check_estimator=False,
                                                        random_state=random_state),
    #     'Feature Bagging': FeatureBagging(LOF(n_neighbors=35), contamination=outliers_fraction, random_state=random_state),
    'Histogram-base Outlier Detection (HBOS)': HBOS(contamination=outliers_fraction),
    'Isolation Forest': IForest(contamination=outliers_fraction, random_state=random_state),
    'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),
    #     'Average KNN': KNN(method='mean', contamination=outliers_fraction),
    'Local Outlier Factor (LOF)': LOF(n_neighbors=35, contamination=outliers_fraction),
    'Minimum Covariance Determinant (MCD)': MCD(contamination=outliers_fraction, random_state=random_state),
    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),
    'Principal Component Analysis (PCA)': PCA(contamination=outliers_fraction, random_state=random_state),
    # 'Locally Selective Combination (LSCP)': LSCP(detector_list, contamination=outliers_fraction, random_state=random_state)
}

for i, (clf_name, clf) in enumerate(classifiers.items()):
    # fit the data and tag outliers
    clf.fit(Xgu)
    scores_pred = clf.decision_function(Xgu) * -1
    y_pred = clf.predict(Xgu)
    threshold = percentile(scores_pred, 100 * outliers_fraction)
    f1 = f1_score(ground_truth, y_pred, average="binary")
    print(i + 1, 'fitting', clf_name, f1)

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xgaussian_t)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xgu, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('ss_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xgu, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('ss_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xgu, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('ss_kd_rpca - F1: %6.2f' % (kd_f1))

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xgaussian_tc)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xgu, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('css_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xgu, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('css_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xgu, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('css_kd_rpca - F1: %6.2f' % (kd_f1))

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xgu)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xgu, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('u_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xgu, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('u_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xgu, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('u_kd_rpca - F1: %6.2f' % (kd_f1))

# Pareto distribution
np.random.seed(42)
a = 3.  # shape
m = 1.  # mode

p1 = (np.random.pareto(a, n_inliers) + 1) * m
p2 = (np.random.pareto(a, n_inliers) + 1) * m
Xpareto = np.vstack((p1, p2)).transpose()
print('Xpareto:', Xpareto.shape)

count, bins, _ = plt.hist(p1, 100, density=True)
fit = a * m ** a / bins ** (a + 1)
plt.plot(bins, max(count) * fit / max(fit), linewidth=2, color='r', label="Pareto")
# plt.savefig("%sPareto1.png" % result_path)
plt.show()
plt.close()
count, bins, _ = plt.hist(p2, 100, density=True)
fit = a * m ** a / bins ** (a + 1)
plt.plot(bins, max(count) * fit / max(fit), linewidth=2, color='r', label="Pareto")
# plt.savefig("%sPareto2.png" % result_path)
plt.show()
plt.close()

p1 = (np.random.pareto(a, n_inliers) + 1) * m
p2 = (np.random.pareto(a, n_inliers) + 1) * m
Xpareto_t = np.vstack((p1, p2)).transpose()
print('Xpareto_t:', Xpareto_t.shape)

# Add outliers
Cgaussian = 0.1 * np.random.randn(n_outliers, 2)
print('Cgaussian:', Cgaussian.shape)
Xpg = np.r_[Xpareto, Cgaussian]
print('Xpg:', Xpg.shape)

np.random.seed(42)
Ct = 0.1 * np.random.randn(n_outliers, 2)
Xpareto_tc = np.r_[Xpareto_t, Ct]

print('### Pareto contaminated by Gaussian')
# Compare given detectors under given settings
# Initialize the data
xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))
ground_truth = np.zeros(n_samples, dtype=int)
ground_truth[-n_outliers:] = 1

# initialize a set of detectors for LSCP
detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),
                 LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),
                 LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),
                 LOF(n_neighbors=50)]

# Show the statics of the data
print('Number of inliers: %i' % n_inliers)
print('Number of outliers: %i' % n_outliers)
print('Contamination: %6.2f' % outliers_fraction)

random_state = np.random.RandomState(42)
# Define nine outlier detection tools to be compared
classifiers = {
    #     'Angle-based Outlier Detector (ABOD)': ABOD(contamination=outliers_fraction),
    'Cluster-based Local Outlier Factor (CBLOF)': CBLOF(contamination=outliers_fraction, check_estimator=False,
                                                        random_state=random_state),
    #     'Feature Bagging': FeatureBagging(LOF(n_neighbors=35), contamination=outliers_fraction, random_state=random_state),
    'Histogram-base Outlier Detection (HBOS)': HBOS(contamination=outliers_fraction),
    'Isolation Forest': IForest(contamination=outliers_fraction, random_state=random_state),
    'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),
    #     'Average KNN': KNN(method='mean', contamination=outliers_fraction),
    'Local Outlier Factor (LOF)': LOF(n_neighbors=35, contamination=outliers_fraction),
    'Minimum Covariance Determinant (MCD)': MCD(contamination=outliers_fraction, random_state=random_state),
    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),
    'Principal Component Analysis (PCA)': PCA(contamination=outliers_fraction, random_state=random_state),
    # 'Locally Selective Combination (LSCP)': LSCP(detector_list, contamination=outliers_fraction, random_state=random_state)
}

clusters_separation = [0]

# Fit the models with the generated data and
# compare model performances
for i, offset in enumerate(clusters_separation):

    # Fit the model
    plt.figure(figsize=(15, 12))
    for i, (clf_name, clf) in enumerate(classifiers.items()):
        # fit the data and tag outliers
        clf.fit(Xpg)
        scores_pred = clf.decision_function(Xpg) * -1
        y_pred = clf.predict(Xpg)
        threshold = percentile(scores_pred, 100 * outliers_fraction)
        # n_errors = (y_pred != ground_truth).sum()
        f1 = f1_score(ground_truth, y_pred, average="binary")
        print(i + 1, 'fitting', clf_name, f1)

    #        # plot the levels lines and the points
#        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1
#        Z = Z.reshape(xx.shape)
#        subplot = plt.subplot(3, 4, i + 1)
#        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),
#                         cmap=plt.cm.Blues_r)
#        a = subplot.contour(xx, yy, Z, levels=[threshold],
#                            linewidths=2, colors='red')
#        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],
#                         colors='orange')
#        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white',
#                            s=20, edgecolor='k')
#        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black',
#                            s=20, edgecolor='k')
#        subplot.axis('tight')
#        subplot.legend(
#            [a.collections[0], b, c],
#            ['learned decision function', 'true inliers', 'true outliers'],
#            prop=matplotlib.font_manager.FontProperties(size=10),
#            loc='lower right')
#        subplot.set_xlabel("%d. %s (errors: %d)" % (i + 1, clf_name, n_errors))
#       subplot.set_xlim((-7, 7))
#        subplot.set_ylim((-7, 7))
#    plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)
#    plt.suptitle("Outlier detection")
# plt.savefig('ALL.png', dpi=300)
# plt.show()


# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xpareto_t)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xpg, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('ss_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xpg, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('ss_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xpg, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('ss_kd_rpca - F1: %6.2f' % (kd_f1))

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xpareto_tc)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xpg, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('css_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xpg, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('css_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xpg, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('css_kd_rpca - F1: %6.2f' % (kd_f1))

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xpg)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xpg, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('u_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xpg, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('u_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xpg, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('u_kd_rpca - F1: %6.2f' % (kd_f1))

sns.distplot(Xpareto[:, 0], color="blue", label="Pareto")
plt.legend()
# plt.savefig("%sXpareto3.png" % result_path)
plt.show()
plt.close()
print('Xpg', Xpg.shape)
sns.distplot(Xpg[:, 0], color="blue", label="Pareto + Gaussian")
plt.legend()
# plt.savefig("%sXpg1.png" % result_path)
plt.show()
plt.close()
sns.distplot(Xpareto[:, 0], color="blue", label="Pareto")
sns.distplot(Cgaussian[:, 0], color="red", label="Gaussian")
plt.legend()
# plt.savefig("%sXpg2.png" % result_path)
plt.show()
plt.close()

mu = 0.  # mean
sigma = 1.  # standard deviation

ln1 = np.random.lognormal(mu, sigma, n_inliers)
count, bins, ignored = plt.hist(ln1, 100, density=True, align='mid')
x = np.linspace(min(bins), max(bins), 10000)
pdf = (np.exp(-(np.log(x) - mu) ** 2 / (2 * sigma ** 2)) / (x * sigma * np.sqrt(2 * np.pi)))
plt.plot(x, pdf, linewidth=2, color='r', label="Lognormal")
plt.axis('tight')
# plt.savefig("%sLognormal1.png" % result_path)
plt.show()
plt.close()

ln2 = np.random.lognormal(mu, sigma, n_inliers)
count, bins, ignored = plt.hist(ln2, 100, density=True, align='mid')
x = np.linspace(min(bins), max(bins), 10000)
pdf = (np.exp(-(np.log(x) - mu) ** 2 / (2 * sigma ** 2)) / (x * sigma * np.sqrt(2 * np.pi)))
plt.plot(x, pdf, linewidth=2, color='r', label="Lognormal")
plt.axis('tight')
# plt.savefig("%sLognormal2.png" % result_path)
plt.show()
plt.close()

Xlogn = np.vstack((ln1, ln2)).transpose()
print('Xlogn:', Xlogn.shape)

# Add gaussian outliers
Xlogng = np.r_[Xlogn, Cgaussian]

ln1 = np.random.lognormal(mu, sigma, n_inliers)
ln2 = np.random.lognormal(mu, sigma, n_inliers)
Xlogn_t = np.vstack((ln1, ln2)).transpose()

np.random.seed(42)
Xlogn_tc = np.r_[Xlogn_t, Ct]

print('### Log-normal contaminated by Gaussian')

# Compare given detectors under given settings
# Initialize the data
xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))
ground_truth = np.zeros(n_samples, dtype=int)
ground_truth[-n_outliers:] = 1

# initialize a set of detectors for LSCP
detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),
                 LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),
                 LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),
                 LOF(n_neighbors=50)]

# Show the statics of the data
print('Number of inliers: %i' % n_inliers)
print('Number of outliers: %i' % n_outliers)
print('Contamination: %6.2f' % outliers_fraction)

random_state = np.random.RandomState(42)
# Define nine outlier detection tools to be compared
classifiers = {
    #     'Angle-based Outlier Detector (ABOD)': ABOD(contamination=outliers_fraction),
    'Cluster-based Local Outlier Factor (CBLOF)': CBLOF(contamination=outliers_fraction, check_estimator=False,
                                                        random_state=random_state),
    #     'Feature Bagging': FeatureBagging(LOF(n_neighbors=35), contamination=outliers_fraction, random_state=random_state),
    'Histogram-base Outlier Detection (HBOS)': HBOS(contamination=outliers_fraction),
    'Isolation Forest': IForest(contamination=outliers_fraction, random_state=random_state),
    'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),
    #     'Average KNN': KNN(method='mean', contamination=outliers_fraction),
    'Local Outlier Factor (LOF)': LOF(n_neighbors=35, contamination=outliers_fraction),
    'Minimum Covariance Determinant (MCD)': MCD(contamination=outliers_fraction, random_state=random_state),
    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),
    'Principal Component Analysis (PCA)': PCA(contamination=outliers_fraction, random_state=random_state),
    # 'Locally Selective Combination (LSCP)': LSCP(detector_list, contamination=outliers_fraction, random_state=random_state)
}

clusters_separation = [0]

# Fit the models with the generated data and
# compare model performances
for i, offset in enumerate(clusters_separation):

    # Fit the model
    plt.figure(figsize=(15, 12))
    for i, (clf_name, clf) in enumerate(classifiers.items()):
        # fit the data and tag outliers
        clf.fit(Xlogng)
        scores_pred = clf.decision_function(Xlogng) * -1
        y_pred = clf.predict(Xlogng)
        threshold = percentile(scores_pred, 100 * outliers_fraction)
        # n_errors = (y_pred != ground_truth).sum()
        f1 = f1_score(ground_truth, y_pred, average="binary")
        print(i + 1, 'fitting', clf_name, f1)

    #        # plot the levels lines and the points
#        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1
#        Z = Z.reshape(xx.shape)
#        subplot = plt.subplot(3, 4, i + 1)
#        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),
#                         cmap=plt.cm.Blues_r)
#        a = subplot.contour(xx, yy, Z, levels=[threshold],
#                            linewidths=2, colors='red')
#        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],
#                         colors='orange')
#        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white',
#                            s=20, edgecolor='k')
#        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black',
#                            s=20, edgecolor='k')
#        subplot.axis('tight')
#        subplot.legend(
#            [a.collections[0], b, c],
#            ['learned decision function', 'true inliers', 'true outliers'],
#            prop=matplotlib.font_manager.FontProperties(size=10),
#            loc='lower right')
#        subplot.set_xlabel("%d. %s (errors: %d)" % (i + 1, clf_name, n_errors))
#       subplot.set_xlim((-7, 7))
#        subplot.set_ylim((-7, 7))
#    plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)
#    plt.suptitle("Outlier detection")
# plt.savefig('ALL.png', dpi=300)
# plt.show()


# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xlogn_t)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xlogng, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('ss_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xlogng, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('ss_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xlogng, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('ss_kd_rpca - F1: %6.2f' % (kd_f1))

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xlogn_tc)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xlogng, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('css_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xlogng, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('css_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xlogng, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('css_kd_rpca - F1: %6.2f' % (kd_f1))

# Train
r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xlogng)
# Testing md-rpca
md_pred_label = md_rpca_prediction(Xlogng, r_mu, r_precision, outliers_fraction)
md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
print('u_md_rpca - F1: %6.2f' % (md_f1))
# Testing sd-rpca
sd_pred_label = sd_rpca_prediction(Xlogng, r_skew, r_precision, outliers_fraction)
sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
print('u_sd_rpca - F1: %6.2f' % (sd_f1))
# Testing kd-rpca
kd_pred_label = kd_rpca_prediction(Xlogng, r_kurt, r_precision, outliers_fraction)
kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
print('u_kd_rpca - F1: %6.2f' % (kd_f1))

sns.distplot(Xlogn[:, 0], color="blue", label="Lognormal")
plt.legend()
# plt.savefig("%sXlogn.png" % result_path)
plt.show()
plt.close()
print('Xlogn_t', Xlogn_t.shape)
sns.distplot(Xlogn_t[:, 0], color="blue", label="Lognormal")
plt.legend()
# plt.savefig("%sXlogn_t.png" % result_path)
plt.show()
plt.close()
print('Xlogng', Xlogng.shape)
sns.distplot(Xlogng[:, 0], color="blue", label="Lognormal+Gaussian")
plt.legend()
# plt.savefig("%sXlogng1.png" % result_path)
plt.show()
plt.close()
sns.distplot(Xlogn[:, 0], color="blue", label="Lognormal")
sns.distplot(Cgaussian[:, 0], color="red", label="Gaussian")
plt.legend()
# plt.savefig("%sXlogng2.png" % result_path)
plt.show()
plt.close()

result_file_path = "%sgaussian_f1_contamination.png" % result_path
if not os.path.isfile(result_file_path):
    # configure GridSearchCV for Gaussian + Uniform
    cv_df = pd.DataFrame()
    for m_contamination in np.linspace(0.01, 0.50, 50):
        outliers_fraction = m_contamination
    
        # Initialize the data
        n_inliers = int((1. - outliers_fraction) * n_samples)
        n_outliers = int(n_samples - n_inliers)
        ground_truth = np.zeros(n_samples, dtype=int)
        ground_truth[-n_outliers:] = 1  # put outliers into the end
    
        # gaussian
        gaussian_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'gaussian', n_samples, m_contamination,)
        if not os.path.isfile(gaussian_df_name):
            np.random.seed(11)
            X1 = 0.3 * np.random.randn(n_inliers, 2)
            X2 = 0.3 * np.random.randn(n_inliers, 2)
            gaussian = np.r_[X1, X2]
            gaussian_df = pd.DataFrame(gaussian)
            gaussian_df.to_csv(gaussian_df_name, index=False)
        else:
            gaussian_df = pd.read_csv(gaussian_df_name)
            gaussian = gaussian_df.values
    
        # Gaussian for training
        gaussian_t = gaussian[:n_inliers]
    
        # Gaussian
        gaussian = gaussian[n_inliers:]
    
        # uniform_c
        uniform_c_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'uniform_c', n_samples, m_contamination,)
        if not os.path.isfile(uniform_c_df_name):
            np.random.seed(111)
            uniform_c = np.random.uniform(low=-6, high=6, size=(n_outliers, 2))
            uniform_c_df = pd.DataFrame(uniform_c)
            uniform_c_df.to_csv(uniform_c_df_name, index=False)
        else:
            uniform_c_df = pd.read_csv(uniform_c_df_name)
            uniform_c = uniform_c_df.values
    
        # uniform_c_t
        uniform_c_t_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'uniform_c_t', n_samples, m_contamination,)
        if not os.path.isfile(uniform_c_t_df_name):
            np.random.seed(110)
            uniform_c_t = np.random.uniform(low=-6, high=6, size=(n_outliers, 2))
            uniform_c_t_df = pd.DataFrame(uniform_c_t)
            uniform_c_t_df.to_csv(uniform_c_t_df_name, index=False)
        else:
            uniform_c_t_df = pd.read_csv(uniform_c_t_df_name)
            uniform_c_t = uniform_c_t_df.values
    
        # Gaussian and uniform anomalies
        Xgu = np.r_[gaussian, uniform_c]
    
        # Contaminated Gaussian for training
        Xgaussian_tc = np.r_[gaussian_t, uniform_c_t]
    
        # initialize a set of detectors for LSCP
        detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),
                         LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),
                         LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),
                         LOF(n_neighbors=50)]
        random_state = np.random.RandomState(42)
    
        # Define nine outlier detection tools to be compared
        classifiers = {
            'IF': IForest(contamination=outliers_fraction, random_state=random_state),
            'KNN': KNN(contamination=outliers_fraction),
            'LOF': LOF(n_neighbors=35, contamination=outliers_fraction),
            'MCD': MCD(contamination=outliers_fraction, random_state=random_state),
            'OCSVM': OCSVM(contamination=outliers_fraction),
            'PCA': PCA(contamination=outliers_fraction, random_state=random_state),
        }
    
        for i, (clf_name, clf) in enumerate(classifiers.items()):
            # fit the data and tag outliers
            clf.fit(Xgu)
            scores_pred = clf.decision_function(Xgu) * -1
            y_pred = clf.predict(Xgu)
            threshold = percentile(scores_pred, 100 * outliers_fraction)
            f1 = f1_score(ground_truth, y_pred, average="binary")
            cv_df = cv_df.append({'F-measure': f1, 'Contamination': outliers_fraction, 'Algorithm': clf_name},
                                 ignore_index=True)
    
        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(gaussian)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xgu, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ss_md-rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xgu, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ss_sd-rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xgu, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ks_md-rpca'},
                             ignore_index=True)
    
        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xgaussian_tc)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xgu, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_md_rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xgu, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_sd_rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xgu, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_kd_rpca'},
                             ignore_index=True)
    
        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xgu)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xgu, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_md_rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xgu, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_sd_rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xgu, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_kd_rpca'},
                             ignore_index=True)
    
        # ROBPCA-AO from saved files
        robpca_result_file = 'output/simulation/robpca/robpca_k2_gaussian_2400_%.2f.csv' % m_contamination
        if os.path.isfile(robpca_result_file):
            # print(robpca_result_file)
            robpca_pred = pd.read_csv(robpca_result_file, header=None)
            robpca_pred = robpca_pred[0]
            robpca_pred[robpca_pred == True] = -1
            robpca_pred[robpca_pred == False] = 1
            robpca_pred[robpca_pred == -1] = 0
            robpca_f1 = f1_score(ground_truth, robpca_pred)
            cv_df = cv_df.append({'F-measure': robpca_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ROBPCA'},
                                 ignore_index=True)
    
    dash_styles = ["",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   ""
                   ]
    fig_dims = (8, 8)
    colors = ["black", "black", "black", "amber", "amber", "amber", "blue", "blue",
              "blue", "red", "red", "red", "green", "green", "green", "cyan"]
    sns.set_style("whitegrid")
    fig, ax = plt.subplots(figsize=fig_dims)
    ax = sns.lineplot(ax=ax, x="Contamination", y="F-measure", hue="Algorithm",
                      style="Algorithm", dashes=dash_styles,
                      palette=sns.xkcd_palette(colors), lw=2,
                      data=cv_df)
    # Put the legend out of the figure
    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
    plt.savefig("%sgaussian_f1_contamination.png" % result_path,  bbox_inches='tight')


result_file_path = "%spareto_f1_contamination.png" % result_path
if not os.path.isfile(result_file_path):
    # configure GridSearchCV for Pareto + Guassian
    cv_df = pd.DataFrame()
    for m_contamination in np.linspace(0.01, 0.50, 50):
        outliers_fraction = m_contamination
    
        # Initialize the data
        n_inliers = int((1. - outliers_fraction) * n_samples)
        n_outliers = int(n_samples - n_inliers)
        ground_truth = np.zeros(n_samples, dtype=int)
        ground_truth[-n_outliers:] = 1  # put outliers into the end
    
        a = 3.  # shape
        m = 1.  # mode
    
        # Pareto
        pareto_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'pareto', n_samples, m_contamination,)
        if not os.path.isfile(pareto_df_name):
            np.random.seed(42)
            p1 = (np.random.pareto(a, n_inliers) + 1) * m
            p2 = (np.random.pareto(a, n_inliers) + 1) * m
            pareto = np.vstack((p1, p2)).transpose()
            pareto_df = pd.DataFrame(pareto)
            pareto_df.to_csv(pareto_df_name, index=False)
        else:
            pareto_df = pd.read_csv(pareto_df_name)
            pareto = pareto_df.values
    
        # Pareto_t
        pareto_t_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'pareto_t', n_samples, m_contamination,)
        if not os.path.isfile(pareto_t_df_name):
            np.random.seed(12)
            p1 = (np.random.pareto(a, n_inliers) + 1) * m
            p2 = (np.random.pareto(a, n_inliers) + 1) * m
            pareto_t = np.vstack((p1, p2)).transpose()
            pareto_t_df = pd.DataFrame(pareto_t)
            pareto_t_df.to_csv(pareto_t_df_name, index=False)
        else:
            pareto_t_df = pd.read_csv(pareto_t_df_name)
            pareto_t = pareto_t_df.values
    
        # gaussian_c
        gaussian_c_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'gaussian_c', n_samples, m_contamination,)
        if not os.path.isfile(gaussian_c_df_name):
            np.random.seed(2)
            gaussian_c = 0.1 * np.random.randn(n_outliers, 2)
            gaussian_c_df = pd.DataFrame(gaussian_c)
            gaussian_c_df.to_csv(gaussian_c_df_name, index=False)
        else:
            gaussian_c_df = pd.read_csv(gaussian_c_df_name)
            gaussian_c = gaussian_c_df.values
    
        # gaussian_c_t
        gaussian_c_t_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'gaussian_c_t', n_samples, m_contamination,)
        if not os.path.isfile(gaussian_c_t_df_name):
            np.random.seed(20)
            gaussian_c_t = 0.1 * np.random.randn(n_outliers, 2)
            gaussian_c_t_df = pd.DataFrame(gaussian_c_t)
            gaussian_c_t_df.to_csv(gaussian_c_t_df_name, index=False)
        else:
            gaussian_c_t_df = pd.read_csv(gaussian_c_t_df_name)
            gaussian_c_t = gaussian_c_t_df.values
    
        # Pareto and gaussian anomalies
        Xpg = np.r_[pareto, gaussian_c]
    
        # Contaminated Pareto for training
        Xpareto_tc = np.r_[pareto_t, gaussian_c_t]
    
        # initialize a set of detectors for LSCP
        detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),
                         LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),
                         LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),
                         LOF(n_neighbors=50)]
        random_state = np.random.RandomState(42)
    
        # Define nine outlier detection tools to be compared
        classifiers = {
            'IF': IForest(contamination=outliers_fraction, random_state=random_state),
            'KNN': KNN(contamination=outliers_fraction),
            'LOF': LOF(n_neighbors=35, contamination=outliers_fraction),
            'MCD': MCD(contamination=outliers_fraction, random_state=random_state),
            'OCSVM': OCSVM(contamination=outliers_fraction),
            'PCA': PCA(contamination=outliers_fraction, random_state=random_state),
        }
    
        for i, (clf_name, clf) in enumerate(classifiers.items()):
            # fit the data and tag outliers
            clf.fit(Xpg)
            scores_pred = clf.decision_function(Xpg) * -1
            y_pred = clf.predict(Xpg)
            threshold = percentile(scores_pred, 100 * outliers_fraction)
            f1 = f1_score(ground_truth, y_pred, average="binary")
            cv_df = cv_df.append({'F-measure': f1, 'Contamination': outliers_fraction, 'Algorithm': clf_name},
                                 ignore_index=True)
    
        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(pareto)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xpg, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ss_md-rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xpg, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ss_sd-rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xpg, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ks_md-rpca'},
                             ignore_index=True)
    
        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xpareto_tc)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xpg, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_md_rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xpg, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_sd_rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xpg, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_kd_rpca'},
                             ignore_index=True)
    
        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xpg)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xpg, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_md_rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xpg, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_sd_rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xpg, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_kd_rpca'},
                             ignore_index=True)
    
        # ROBPCA-AO from saved files
        robpca_result_file = 'output/simulation/robpca/robpca_k2_pareto_2400_%.2f.csv' % m_contamination
        if os.path.isfile(robpca_result_file):
            robpca_pred = pd.read_csv(robpca_result_file, header=None)
            robpca_pred = robpca_pred[0]
            robpca_pred[robpca_pred == True] = -1
            robpca_pred[robpca_pred == False] = 1
            robpca_pred[robpca_pred == -1] = 0
            robpca_f1 = f1_score(ground_truth, robpca_pred)
            cv_df = cv_df.append({'F-measure': robpca_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ROBPCA'},
                                 ignore_index=True)
        
    dash_styles = ["",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   ""
                   ]
    fig_dims = (8, 8)
    colors = ["black", "black", "black", "amber", "amber", "amber", "blue", "blue",
              "blue", "red", "red", "red", "green", "green", "green", "cyan"]
    sns.set_style("whitegrid")
    fig, ax = plt.subplots(figsize=fig_dims)
    ax = sns.lineplot(ax=ax, x="Contamination", y="F-measure", hue="Algorithm",
                      style="Algorithm", dashes=dash_styles,
                      palette=sns.xkcd_palette(colors), lw=2,
                      data=cv_df)
    # Put the legend out of the figure
    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
    plt.savefig("%spareto_f1_contamination.png" % result_path,  bbox_inches='tight')


result_file_path = "%slognormal_f1_contamination.png" % result_path
if not os.path.isfile(result_file_path):
    # configure GridSearchCV for Lognormal + Guassian
    cv_df = pd.DataFrame()
    for m_contamination in np.linspace(0.01, 0.50, 50):
        outliers_fraction = m_contamination

        # Initialize the data
        n_inliers = int((1. - outliers_fraction) * n_samples)
        n_outliers = int(n_samples - n_inliers)
        ground_truth = np.zeros(n_samples, dtype=int)
        ground_truth[-n_outliers:] = 1  # put outliers into the end

        mu = 0.  # Lognormal mean
        sigma = 1.  # Lognormal standard deviation

        # Lognormal
        lognormal_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'lognormal', n_samples, m_contamination,)
        if not os.path.isfile(lognormal_df_name):
            np.random.seed(42)
            ln1 = np.random.lognormal(mu, sigma, n_inliers)
            ln2 = np.random.lognormal(mu, sigma, n_inliers)
            lognormal = np.vstack((ln1, ln2)).transpose()
            lognormal_df = pd.DataFrame(lognormal)
            lognormal_df.to_csv(lognormal_df_name, index=False)
        else:
            lognormal_df = pd.read_csv(lognormal_df_name)
            lognormal = lognormal_df.values

        # Lognormal_t
        lognormal_t_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'lognormal_t', n_samples, m_contamination,)
        if not os.path.isfile(lognormal_t_df_name):
            np.random.seed(142)
            ln1 = np.random.lognormal(mu, sigma, n_inliers)
            ln2 = np.random.lognormal(mu, sigma, n_inliers)
            lognormal_t = np.vstack((ln1, ln2)).transpose()
            lognormal_t_df = pd.DataFrame(lognormal_t)
            lognormal_t_df.to_csv(lognormal_t_df_name, index=False)
        else:
            lognormal_t_df = pd.read_csv(lognormal_t_df_name)
            lognormal_t = lognormal_t_df.values

        # gaussian_c
        gaussian_c_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'gaussian_c', n_samples, m_contamination,)
        if not os.path.isfile(gaussian_c_df_name):
            np.random.seed(2)
            gaussian_c = 0.1 * np.random.randn(n_outliers, 2)
            gaussian_c_df = pd.DataFrame(gaussian_c)
            gaussian_c_df.to_csv(gaussian_c_df_name, index=False)
        else:
            gaussian_c_df = pd.read_csv(gaussian_c_df_name)
            gaussian_c = gaussian_c_df.values

        # gaussian_c_t
        gaussian_c_t_df_name = "%s/%s_%d_%6.2f.csv" % (data_path, 'gaussian_c_t', n_samples, m_contamination,)
        if not os.path.isfile(gaussian_c_t_df_name):
            np.random.seed(20)
            gaussian_c_t = 0.1 * np.random.randn(n_outliers, 2)
            gaussian_c_t_df = pd.DataFrame(gaussian_c_t)
            gaussian_c_t_df.to_csv(gaussian_c_t_df_name, index=False)
        else:
            gaussian_c_t_df = pd.read_csv(gaussian_c_t_df_name)
            gaussian_c_t = gaussian_c_t_df.values

        # Lognormal and gaussian anomalies
        Xlogng = np.r_[lognormal, gaussian_c]

        # Contaminated Lognormal for training
        Xlogn_tc = np.r_[lognormal_t, gaussian_c_t]

        # initialize a set of detectors for LSCP
        detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),
                         LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),
                         LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),
                         LOF(n_neighbors=50)]
        random_state = np.random.RandomState(42)

        # Define nine outlier detection tools to be compared
        classifiers = {
            'IF': IForest(contamination=outliers_fraction, random_state=random_state),
            'KNN': KNN(contamination=outliers_fraction),
            'LOF': LOF(n_neighbors=35, contamination=outliers_fraction),
            'MCD': MCD(contamination=outliers_fraction, random_state=random_state),
            'OCSVM': OCSVM(contamination=outliers_fraction),
            'PCA': PCA(contamination=outliers_fraction, random_state=random_state),
        }

        for i, (clf_name, clf) in enumerate(classifiers.items()):
            # fit the data and tag outliers
            clf.fit(Xlogng)
            scores_pred = clf.decision_function(Xlogng) * -1
            y_pred = clf.predict(Xlogng)
            threshold = percentile(scores_pred, 100 * outliers_fraction)
            f1 = f1_score(ground_truth, y_pred, average="binary")
            cv_df = cv_df.append({'F-measure': f1, 'Contamination': outliers_fraction, 'Algorithm': clf_name},
                                 ignore_index=True)

        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(lognormal_t)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xlogng, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ss_md-rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xlogng, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ss_sd-rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xlogng, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ks_md-rpca'},
                             ignore_index=True)

        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xlogn_tc)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xlogng, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_md_rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xlogng, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_sd_rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xlogng, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'css_kd_rpca'},
                             ignore_index=True)

        # Train
        r_L, r_mu, r_cov, r_dist, r_precision, r_skew, _, r_kurt, _ = fit_m_rpca(Xlogng)
        # Testing md-rpca
        md_pred_label = md_rpca_prediction(Xlogng, r_mu, r_precision, outliers_fraction)
        md_f1 = f1_score(ground_truth, md_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': md_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_md_rpca'},
                             ignore_index=True)
        # Testing sd-rpca
        sd_pred_label = sd_rpca_prediction(Xlogng, r_skew, r_precision, outliers_fraction)
        sd_f1 = f1_score(ground_truth, sd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': sd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_sd_rpca'},
                             ignore_index=True)
        # Testing kd-rpca
        kd_pred_label = kd_rpca_prediction(Xlogng, r_kurt, r_precision, outliers_fraction)
        kd_f1 = f1_score(ground_truth, kd_pred_label, average="binary")
        cv_df = cv_df.append({'F-measure': kd_f1, 'Contamination': outliers_fraction, 'Algorithm': 'u_kd_rpca'},
                             ignore_index=True)

        # ROBPCA-AO from saved files
        robpca_result_file = 'output/simulation/robpca/robpca_k2_lognormal_2400_%.2f.csv' % m_contamination
        if os.path.isfile(robpca_result_file):
            robpca_pred = pd.read_csv(robpca_result_file, header=None)
            robpca_pred = robpca_pred[0]
            robpca_pred[robpca_pred == True] = -1
            robpca_pred[robpca_pred == False] = 1
            robpca_pred[robpca_pred == -1] = 0
            robpca_f1 = f1_score(ground_truth, robpca_pred)
            cv_df = cv_df.append({'F-measure': robpca_f1, 'Contamination': outliers_fraction, 'Algorithm': 'ROBPCA'},
                                 ignore_index=True)

    dash_styles = ["",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   "",
                   (1, 1),
                   (5, 2),
                   ""
                   ]
    fig_dims = (8, 8)
    colors = ["black", "black", "black", "amber", "amber", "amber", "blue", "blue",
              "blue", "red", "red", "red", "green", "green", "green", "cyan"]
    sns.set_style("whitegrid")
    fig, ax = plt.subplots(figsize=fig_dims)
    ax = sns.lineplot(ax=ax, x="Contamination", y="F-measure", hue="Algorithm",
                      style="Algorithm", dashes=dash_styles,
                      palette=sns.xkcd_palette(colors), lw=2,
                      data=cv_df)
    # Put the legend out of the figure
    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
    plt.savefig("%slognormal_f1_contamination.png" % result_path,  bbox_inches='tight')


for m_contamination in [0.10, 0.25, 0.33]:

    # Initialize the data
    outliers_fraction = m_contamination
    n_inliers = int((1. - outliers_fraction) * n_samples)
    n_outliers = int(n_samples - n_inliers)
    ground_truth = np.zeros(n_samples, dtype=int)
    ground_truth[-n_outliers:] = 1  # put outliers into the end

    robpca_result_file = 'output/simulation/robpca/robpca_k2_gaussian_2400_%.2f.csv' % m_contamination
    if os.path.isfile(robpca_result_file):
        robpca_pred = pd.read_csv(robpca_result_file, header=None)
        robpca_pred = robpca_pred[0]
        robpca_pred[robpca_pred == True] = -1
        robpca_pred[robpca_pred == False] = 1
        robpca_pred[robpca_pred == -1] = 0
        robpca_f1 = f1_score(ground_truth, robpca_pred)
        print('robpca_k2_gaussian_2400_%.2f: %.2f' % (m_contamination, robpca_f1))

    robpca_result_file = 'output/simulation/robpca/robpca_k2_pareto_2400_%.2f.csv' % m_contamination
    if os.path.isfile(robpca_result_file):
        robpca_pred = pd.read_csv(robpca_result_file, header=None)
        robpca_pred = robpca_pred[0]
        robpca_pred[robpca_pred == True] = -1
        robpca_pred[robpca_pred == False] = 1
        robpca_pred[robpca_pred == -1] = 0
        robpca_f1 = f1_score(ground_truth, robpca_pred)
        print('robpca_k2_pareto_2400_%.2f: %.2f' % (m_contamination, robpca_f1))

    robpca_result_file = 'output/simulation/robpca/robpca_k2_lognormal_2400_%.2f.csv' % m_contamination
    if os.path.isfile(robpca_result_file):
        robpca_pred = pd.read_csv(robpca_result_file, header=None)
        robpca_pred = robpca_pred[0]
        robpca_pred[robpca_pred == True] = -1
        robpca_pred[robpca_pred == False] = 1
        robpca_pred[robpca_pred == -1] = 0
        robpca_f1 = f1_score(ground_truth, robpca_pred)
        print('robpca_k2_lognormal_2400_%.2f: %.2f' % (m_contamination, robpca_f1))
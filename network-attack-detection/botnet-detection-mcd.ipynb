{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# coding=utf-8\n",
    "import os, sys, gc, ipaddress, time, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, make_scorer\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleasing(m_df):\n",
    "    # data cleasing, feature engineering and save clean data into pickles\n",
    "\n",
    "    print('### Data Cleasing and Feature Engineering')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # [Protocol] - Discard ipv6-icmp and categorize\n",
    "    m_df = m_df[m_df.Proto != 'ipv6-icmp']\n",
    "    m_df['Proto'] = m_df['Proto'].fillna('-')\n",
    "    m_df['Proto'] = le.fit_transform(m_df['Proto'])\n",
    "\n",
    "    # [Label] - Categorize\n",
    "    anomalies = m_df.Label.str.contains('Botnet')\n",
    "    normal = np.invert(anomalies)\n",
    "    m_df.loc[anomalies, 'Label'] = np.uint8(1)\n",
    "    m_df.loc[normal, 'Label'] = np.uint8(0)\n",
    "    m_df['Label'] = pd.to_numeric(m_df['Label'])\n",
    "\n",
    "    # [Dport] - replace NaN with 0 port number\n",
    "    m_df['Dport'] = m_df['Dport'].fillna('0')\n",
    "    m_df['Dport'] = m_df['Dport'].apply(lambda x: int(x, 0))\n",
    "\n",
    "    # [sport] - replace NaN with 0 port number\n",
    "    try:\n",
    "        m_df['Sport'] = m_df['Sport'].fillna('0')\n",
    "        m_df['Sport'] = m_df['Sport'].str.replace('.*x+.*', '0')\n",
    "        m_df['Sport'] = m_df['Sport'].apply(lambda x: int(x, 0))\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "\n",
    "    # [sTos] - replace NaN with \"10\" and convert to int\n",
    "    m_df['sTos'] = m_df['sTos'].fillna('10')\n",
    "    m_df['sTos'] = m_df['sTos'].astype(int)\n",
    "\n",
    "    # [dTos] - replace NaN with \"10\" and convert to int\n",
    "    m_df['dTos'] = m_df['dTos'].fillna('10')\n",
    "    m_df['dTos'] = m_df['dTos'].astype(int)\n",
    "\n",
    "    # [State] - replace NaN with \"-\" and categorize\n",
    "    m_df['State'] = m_df['State'].fillna('-')\n",
    "    m_df['State'] = le.fit_transform(m_df['State'])\n",
    "\n",
    "    # [Dir] - replace NaN with \"-\" and categorize\n",
    "    m_df['Dir'] = m_df['Dir'].fillna('-')\n",
    "    m_df['Dir'] = le.fit_transform(m_df['Dir'])\n",
    "\n",
    "    # [SrcAddr] Extract subnet features and categorize\n",
    "    m_df['SrcAddr'] = m_df['SrcAddr'].fillna('0.0.0.0')\n",
    "\n",
    "    # [DstAddr] Extract subnet features\n",
    "    m_df['DstAddr'] = m_df['DstAddr'].fillna('0.0.0.0')\n",
    "\n",
    "    # [StartTime] - Parse to datatime, reindex based on StartTime, but first drop the ns off the time stamps\n",
    "    m_df['StartTime'] = m_df['StartTime'].apply(lambda x: x[:19])\n",
    "    m_df['StartTime'] = pd.to_datetime(m_df['StartTime'])\n",
    "\n",
    "    m_df = m_df.set_index('StartTime')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return m_df\n",
    "\n",
    "\n",
    "def classify_ip(ip):\n",
    "    \"\"\"\n",
    "    str ip - ip address string to attempt to classify. treat ipv6 addresses as N/A\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ip_addr = ipaddress.ip_address(ip)\n",
    "        if isinstance(ip_addr, ipaddress.IPv6Address):\n",
    "            return 'ipv6'\n",
    "        elif isinstance(ip_addr, ipaddress.IPv4Address):\n",
    "            # split on .\n",
    "            octs = ip_addr.exploded.split('.')\n",
    "            if 0 < int(octs[0]) < 127:\n",
    "                return 'A'\n",
    "            elif 127 < int(octs[0]) < 192:\n",
    "                return 'B'\n",
    "            elif 191 < int(octs[0]) < 224:\n",
    "                return 'C'\n",
    "            else:\n",
    "                return 'N/A'\n",
    "    except ValueError:\n",
    "        return 'N/A'\n",
    "\n",
    "\n",
    "def avg_duration(x):\n",
    "    return np.average(x)\n",
    "\n",
    "\n",
    "def n_dports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b > 1024 else a), x)\n",
    "\n",
    "\n",
    "n_dports_gt1024.__name__ = 'n_dports>1024'\n",
    "\n",
    "\n",
    "def n_dports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b < 1024 else a), x)\n",
    "\n",
    "\n",
    "n_dports_lt1024.__name__ = 'n_dports<1024'\n",
    "\n",
    "\n",
    "def n_sports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b > 1024 else a), x)\n",
    "\n",
    "\n",
    "n_sports_gt1024.__name__ = 'n_sports>1024'\n",
    "\n",
    "\n",
    "def n_sports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b < 1024 else a), x)\n",
    "\n",
    "\n",
    "n_sports_lt1024.__name__ = 'n_sports<1024'\n",
    "\n",
    "\n",
    "def label_atk_v_norm(x):\n",
    "    for l in x:\n",
    "        if l == 1: return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "label_atk_v_norm.__name__ = 'label'\n",
    "\n",
    "\n",
    "def background_flow_count(x):\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def normal_flow_count(x):\n",
    "    if x.size == 0: return 0\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_conn(x):\n",
    "    return x.size\n",
    "\n",
    "\n",
    "def n_tcp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 10: count += 1  # tcp == 10\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_udp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 11: count += 1  # udp == 11\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_icmp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 1: count += 1  # icmp == 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'B': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_ipv6(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'ipv6': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, y_predic):\n",
    "    m_f1 = f1_score(y_test, y_predic, average=\"binary\")\n",
    "    m_recall = recall_score(y_test, y_predic, average=\"binary\")\n",
    "    m_precision = precision_score(y_test, y_predic, average=\"binary\")\n",
    "    print('\\tF1 Score: ', m_f1, ', Recall: ', m_recall, ', Precision: ,', m_precision)\n",
    "\n",
    "\n",
    "def get_classification_report(y_test, y_predic):\n",
    "    m_f1 = f1_score(y_test, y_predic, average = \"binary\")\n",
    "    m_recall = recall_score(y_test, y_predic, average = \"binary\")\n",
    "    m_precision = precision_score(y_test, y_predic, average = \"binary\")\n",
    "    return m_f1, m_recall, m_precision\n",
    "\n",
    "\n",
    "def data_splitting(m_df, drop_feature):\n",
    "    # drop non discriminant features\n",
    "    m_df.drop(drop_feature, axis=1, inplace=True)\n",
    "\n",
    "    # split into normal and anomaly\n",
    "    df_l1 = m_df[m_df[\"Label\"] == 1]\n",
    "    df_l0 = m_df[m_df[\"Label\"] == 0]\n",
    "    gc.collect()\n",
    "\n",
    "    # Length and indexes\n",
    "    anom_len = len(df_l1)  # total number of anomalous flows\n",
    "    anom_train_end = anom_len // 2  # 50% of anomalous for training\n",
    "    anom_cv_start = anom_train_end + 1  # 50% of anomalous for testing\n",
    "    norm_len = len(df_l0)  # total number of normal flows\n",
    "    norm_train_end = (norm_len * 60) // 100  # 60% of normal for training\n",
    "    norm_cv_start = norm_train_end + 1  # 20% of normal for cross validation\n",
    "    norm_cv_end = (norm_len * 80) // 100  # 20% of normal for cross validation\n",
    "    norm_test_start = norm_cv_end + 1  # 20% of normal for testing\n",
    "\n",
    "    # anomalies split data\n",
    "    anom_cv_df = df_l1[:anom_train_end]  # 50% of anomalies59452\n",
    "    anom_test_df = df_l1[anom_cv_start:anom_len]  # 50% of anomalies\n",
    "    gc.collect()\n",
    "\n",
    "    # normal split data\n",
    "    m_norm_train_df = df_l0[:norm_train_end]  # 60% of normal\n",
    "    norm_cv_df = df_l0[norm_cv_start:norm_cv_end]  # 20% of normal\n",
    "    norm_test_df = df_l0[norm_test_start:norm_len]  # 20% of normal\n",
    "    gc.collect()\n",
    "\n",
    "    # CV and test data. train data is norm_train_df\n",
    "    m_cv_df = pd.concat([norm_cv_df, anom_cv_df], axis=0)\n",
    "    m_test_df = pd.concat([norm_test_df, anom_test_df], axis=0)\n",
    "    gc.collect()\n",
    "\n",
    "    # Sort data by index\n",
    "    m_norm_train_df = m_norm_train_df.sort_index()\n",
    "    m_cv_df = m_cv_df.sort_index()\n",
    "    m_test_df = m_test_df.sort_index()\n",
    "    gc.collect()\n",
    "\n",
    "    # save labels and drop labels from data\n",
    "    m_cv_label = m_cv_df[\"Label\"]\n",
    "    m_test_label = m_test_df[\"Label\"]\n",
    "    m_norm_train_df = m_norm_train_df.drop(labels=[\"Label\"], axis=1)\n",
    "    m_cv_df = m_cv_df.drop(labels=[\"Label\"], axis=1)\n",
    "    m_test_df = m_test_df.drop(labels=[\"Label\"], axis=1)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return m_norm_train_df, m_cv_df, m_test_df, m_cv_label, m_test_label\n",
    "\n",
    "\n",
    "def getBestByNormalCV(t_normal, cv, t_cv_label):\n",
    "\n",
    "    # prepare data\n",
    "    m_cv_label = t_cv_label.astype(np.int8)\n",
    "    m_cv_label[m_cv_label == 1] = -1\n",
    "    m_cv_label[m_cv_label == 0] = 1\n",
    "\n",
    "    # initialize\n",
    "    m_best_model = EllipticEnvelope()\n",
    "    m_best_contamination = 0\n",
    "    m_best_f1 = 0\n",
    "    m_best_precision = 0\n",
    "    m_best_recall = 0\n",
    "\n",
    "    m_contamination = 0.01\n",
    "    # configure GridSearchCV\n",
    "    m_ell_model = EllipticEnvelope(contamination = m_contamination)\n",
    "    m_ell_model.fit(t_normal)\n",
    "    m_pred = m_ell_model.predict(cv)\n",
    "\n",
    "    m_f1 = f1_score(m_cv_label, m_pred, average=\"binary\")\n",
    "    m_recall = recall_score(m_cv_label, m_pred, average=\"binary\")\n",
    "    m_precision = precision_score(m_cv_label, m_pred, average=\"binary\")\n",
    "\n",
    "    if m_f1 > m_best_f1:\n",
    "        m_best_model = m_ell_model\n",
    "        m_best_contamination = m_contamination\n",
    "        m_best_f1 = m_f1\n",
    "        m_best_precision = m_precision\n",
    "        m_best_recall = m_recall\n",
    "\n",
    "    return m_best_model, m_best_contamination, m_best_f1, m_best_precision, m_best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl_fast/capture20110818-2.binetflow\n"
     ]
    }
   ],
   "source": [
    "column_types = {\n",
    "    'StartTime': 'str',\n",
    "    'Dur': 'float32',\n",
    "    'Proto': 'str',\n",
    "    'SrcAddr': 'str',\n",
    "    'Sport': 'str',\n",
    "    'Dir': 'str',\n",
    "    'DstAddr': 'str',\n",
    "    'Dport': 'str',\n",
    "    'State': 'str',\n",
    "    'sTos': 'float16',\n",
    "    'dTos': 'float16',\n",
    "    'TotPkts': 'uint32',\n",
    "    'TotBytes': 'uint32',\n",
    "    'SrcBytes': 'uint32',\n",
    "    'Label': 'uint8'}\n",
    "\n",
    "# feature selection\n",
    "drop_features = {\n",
    "    'drop_features01': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'TotBytes', 'Proto'],\n",
    "    'drop_features02': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'TotBytes'],\n",
    "    'drop_features03': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'Proto'],\n",
    "    'drop_features04': ['SrcAddr', 'DstAddr', 'sTos', 'Proto']\n",
    "}\n",
    "\n",
    "features_key = 'drop_features04'\n",
    "\n",
    "pkl_file_path = '/media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl_fast/capture20110818-2.binetflow'\n",
    "print(\"## Sample File: \", pkl_file_path)\n",
    "df = pd.read_pickle(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "norm_train_df, cv_df, test_df, cv_label, test_label = data_splitting(df, drop_features[features_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[EllipticEnvelope][ drop_features04 ] Cross-Validation. Contamination: 0.01 ,F1: 0.902104972883537 , Recall: 0.9905127169963666 , Precision: 0.8281856540084388\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation and model selection\n",
    "ell_model, best_contamination, best_f1, best_precision, best_recall = getBestByNormalCV(norm_train_df, cv_df, cv_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Cross-Validation. Contamination:',best_contamination,',F1:', best_f1, ', Recall:', best_recall, ', Precision:', best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[EllipticEnvelope][ drop_features04 ] Test. F1: 0.9047411718875318 , Recall: 0.9961649089165868 , Precision: 0.8286877676097725\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_label = test_label.astype(np.int8)\n",
    "test_label[test_label == 1] = -1\n",
    "test_label[test_label == 0] = 1\n",
    "pred_test_label = ell_model.predict(test_df)\n",
    "\n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.51490656e-01, 4.08915812e+04, 2.99908312e+00, 7.15269920e+03,\n",
       "       5.00268741e+00, 3.47782099e-03, 2.04135445e+00, 2.18695880e+02,\n",
       "       8.90356951e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell_model.location_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.59687803e+00, -2.66937397e+03,  2.30554144e-04,\n",
       "         2.51271574e+03, -6.69992278e-04, -7.88134217e-04,\n",
       "         4.85416762e-01,  1.98416769e+01,  1.67444751e+01],\n",
       "       [-2.66937397e+03,  2.83575372e+08,  3.74527129e+01,\n",
       "        -8.13183760e+07, -1.09919770e+02, -1.33844887e+02,\n",
       "        -3.45965165e+02,  4.11160181e+05, -8.35799642e+04],\n",
       "       [ 2.30554144e-04,  3.74527129e+01,  2.68656646e-03,\n",
       "         2.70859897e+00, -3.22242452e-03, -9.16561204e-03,\n",
       "         8.91564044e-04,  1.23120571e-01,  4.23772986e-03],\n",
       "       [ 2.51271574e+03, -8.13183760e+07,  2.70859897e+00,\n",
       "         1.04490009e+08, -9.23726428e+00, -3.89724342e+00,\n",
       "         3.75714896e+02, -3.05057058e+05,  9.01414927e+04],\n",
       "       [-6.69992278e-04, -1.09919770e+02, -3.22242452e-03,\n",
       "        -9.23726428e+00,  1.14063540e-02,  1.04241166e-02,\n",
       "        -1.24933221e-03, -2.82435418e-01, -4.57818484e-02],\n",
       "       [-7.88134217e-04, -1.33844887e+02, -9.16561204e-03,\n",
       "        -3.89724342e+00,  1.04241166e-02,  3.24264896e-02,\n",
       "        -2.98931328e-03, -4.29022316e-01,  1.77285213e-03],\n",
       "       [ 4.85416762e-01, -3.45965165e+02,  8.91564044e-04,\n",
       "         3.75714896e+02, -1.24933221e-03, -2.98931328e-03,\n",
       "         1.03446469e-01,  4.82550155e+00,  3.37801735e+00],\n",
       "       [ 1.98416769e+01,  4.11160181e+05,  1.23120571e-01,\n",
       "        -3.05057058e+05, -2.82435418e-01, -4.29022316e-01,\n",
       "         4.82550155e+00,  6.68839754e+03,  6.59844837e+02],\n",
       "       [ 1.67444751e+01, -8.35799642e+04,  4.23772986e-03,\n",
       "         9.01414927e+04, -4.57818484e-02,  1.77285213e-03,\n",
       "         3.37801735e+00,  6.59844837e+02,  1.03431220e+03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell_model.covariance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dur             6.399901\n",
       "Sport       33501.837309\n",
       "Dir             1.778182\n",
       "Dport        9377.413842\n",
       "State          52.797640\n",
       "dTos            2.892292\n",
       "TotPkts        12.550506\n",
       "TotBytes    10525.676333\n",
       "SrcBytes      903.653779\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dur           4.097185\n",
       "Sport        -0.221067\n",
       "Dir          -0.378798\n",
       "Dport         1.978699\n",
       "State         0.843266\n",
       "dTos          0.929891\n",
       "TotPkts     113.704864\n",
       "TotBytes    110.168644\n",
       "SrcBytes     90.120795\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dur            17.287244\n",
       "Sport          -1.326040\n",
       "Dir            -1.826595\n",
       "Dport           3.643176\n",
       "State          -1.093035\n",
       "dTos           -1.135271\n",
       "TotPkts     14429.895694\n",
       "TotBytes    13409.341791\n",
       "SrcBytes     9828.349090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dur             0.00071\n",
       "Sport       36922.00000\n",
       "Dir             3.00000\n",
       "Dport          80.00000\n",
       "State           5.00000\n",
       "dTos            0.00000\n",
       "TotPkts         2.00000\n",
       "TotBytes      257.00000\n",
       "SrcBytes       83.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.location_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[EllipticEnvelope][ drop_features04 ] Test. F1: 0.9047411718875318 , Recall: 0.9961649089165868 , Precision: 0.8286877676097725\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

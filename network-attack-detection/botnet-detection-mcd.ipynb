{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# coding=utf-8\n",
    "import sys, gc, ipaddress, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from functools import reduce\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, pairwise_distances\n",
    "from outlier_detection import MEllipticEnvelope\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleasing(m_df):\n",
    "    # data cleasing, feature engineering and save clean data into pickles\n",
    "\n",
    "    print('### Data Cleasing and Feature Engineering')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # [Protocol] - Discard ipv6-icmp and categorize\n",
    "    m_df = m_df[m_df.Proto != 'ipv6-icmp']\n",
    "    m_df['Proto'] = m_df['Proto'].fillna('-')\n",
    "    m_df['Proto'] = le.fit_transform(m_df['Proto'])\n",
    "\n",
    "    # [Label] - Categorize\n",
    "    anomalies = m_df.Label.str.contains('Botnet')\n",
    "    normal = np.invert(anomalies)\n",
    "    m_df.loc[anomalies, 'Label'] = np.uint8(1)\n",
    "    m_df.loc[normal, 'Label'] = np.uint8(0)\n",
    "    m_df['Label'] = pd.to_numeric(m_df['Label'])\n",
    "\n",
    "    # [Dport] - replace NaN with 0 port number\n",
    "    m_df['Dport'] = m_df['Dport'].fillna('0')\n",
    "    m_df['Dport'] = m_df['Dport'].apply(lambda x: int(x, 0))\n",
    "\n",
    "    # [sport] - replace NaN with 0 port number\n",
    "    try:\n",
    "        m_df['Sport'] = m_df['Sport'].fillna('0')\n",
    "        m_df['Sport'] = m_df['Sport'].str.replace('.*x+.*', '0')\n",
    "        m_df['Sport'] = m_df['Sport'].apply(lambda x: int(x, 0))\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "\n",
    "    # [sTos] - replace NaN with \"10\" and convert to int\n",
    "    m_df['sTos'] = m_df['sTos'].fillna('10')\n",
    "    m_df['sTos'] = m_df['sTos'].astype(int)\n",
    "\n",
    "    # [dTos] - replace NaN with \"10\" and convert to int\n",
    "    m_df['dTos'] = m_df['dTos'].fillna('10')\n",
    "    m_df['dTos'] = m_df['dTos'].astype(int)\n",
    "\n",
    "    # [State] - replace NaN with \"-\" and categorize\n",
    "    m_df['State'] = m_df['State'].fillna('-')\n",
    "    m_df['State'] = le.fit_transform(m_df['State'])\n",
    "\n",
    "    # [Dir] - replace NaN with \"-\" and categorize\n",
    "    m_df['Dir'] = m_df['Dir'].fillna('-')\n",
    "    m_df['Dir'] = le.fit_transform(m_df['Dir'])\n",
    "\n",
    "    # [SrcAddr] Extract subnet features and categorize\n",
    "    m_df['SrcAddr'] = m_df['SrcAddr'].fillna('0.0.0.0')\n",
    "\n",
    "    # [DstAddr] Extract subnet features\n",
    "    m_df['DstAddr'] = m_df['DstAddr'].fillna('0.0.0.0')\n",
    "\n",
    "    # [StartTime] - Parse to datatime, reindex based on StartTime, but first drop the ns off the time stamps\n",
    "    m_df['StartTime'] = m_df['StartTime'].apply(lambda x: x[:19])\n",
    "    m_df['StartTime'] = pd.to_datetime(m_df['StartTime'])\n",
    "\n",
    "    m_df = m_df.set_index('StartTime')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return m_df\n",
    "\n",
    "\n",
    "def classify_ip(ip):\n",
    "    \"\"\"\n",
    "    str ip - ip address string to attempt to classify. treat ipv6 addresses as N/A\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ip_addr = ipaddress.ip_address(ip)\n",
    "        if isinstance(ip_addr, ipaddress.IPv6Address):\n",
    "            return 'ipv6'\n",
    "        elif isinstance(ip_addr, ipaddress.IPv4Address):\n",
    "            # split on .\n",
    "            octs = ip_addr.exploded.split('.')\n",
    "            if 0 < int(octs[0]) < 127:\n",
    "                return 'A'\n",
    "            elif 127 < int(octs[0]) < 192:\n",
    "                return 'B'\n",
    "            elif 191 < int(octs[0]) < 224:\n",
    "                return 'C'\n",
    "            else:\n",
    "                return 'N/A'\n",
    "    except ValueError:\n",
    "        return 'N/A'\n",
    "\n",
    "\n",
    "def avg_duration(x):\n",
    "    return np.average(x)\n",
    "\n",
    "\n",
    "def n_dports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b > 1024 else a), x)\n",
    "\n",
    "\n",
    "n_dports_gt1024.__name__ = 'n_dports>1024'\n",
    "\n",
    "\n",
    "def n_dports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b < 1024 else a), x)\n",
    "\n",
    "\n",
    "n_dports_lt1024.__name__ = 'n_dports<1024'\n",
    "\n",
    "\n",
    "def n_sports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b > 1024 else a), x)\n",
    "\n",
    "\n",
    "n_sports_gt1024.__name__ = 'n_sports>1024'\n",
    "\n",
    "\n",
    "def n_sports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a, b: a + b if b < 1024 else a), x)\n",
    "\n",
    "\n",
    "n_sports_lt1024.__name__ = 'n_sports<1024'\n",
    "\n",
    "\n",
    "def label_atk_v_norm(x):\n",
    "    for l in x:\n",
    "        if l == 1: return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "label_atk_v_norm.__name__ = 'label'\n",
    "\n",
    "\n",
    "def background_flow_count(x):\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def normal_flow_count(x):\n",
    "    if x.size == 0: return 0\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_conn(x):\n",
    "    return x.size\n",
    "\n",
    "\n",
    "def n_tcp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 10: count += 1  # tcp == 10\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_udp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 11: count += 1  # udp == 11\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_icmp(x):\n",
    "    count = 0\n",
    "    for p in x:\n",
    "        if p == 1: count += 1  # icmp == 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'B': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_s_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_d_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def n_ipv6(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'ipv6': count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, y_predic):\n",
    "    m_f1 = f1_score(y_test, y_predic, average=\"binary\")\n",
    "    m_recall = recall_score(y_test, y_predic, average=\"binary\")\n",
    "    m_precision = precision_score(y_test, y_predic, average=\"binary\")\n",
    "    print('\\tF1 Score: ', m_f1, ', Recall: ', m_recall, ', Precision: ,', m_precision)\n",
    "\n",
    "\n",
    "def get_classification_report(y_test, y_predic):\n",
    "    m_f1 = f1_score(y_test, y_predic, average = \"binary\")\n",
    "    m_recall = recall_score(y_test, y_predic, average = \"binary\")\n",
    "    m_precision = precision_score(y_test, y_predic, average = \"binary\")\n",
    "    return m_f1, m_recall, m_precision\n",
    "\n",
    "\n",
    "def data_splitting(m_df, drop_feature):\n",
    "    # drop non discriminant features\n",
    "    m_df.drop(drop_feature, axis=1, inplace=True)\n",
    "\n",
    "    # split into normal and anomaly\n",
    "    df_l1 = m_df[m_df[\"Label\"] == 1]\n",
    "    df_l0 = m_df[m_df[\"Label\"] == 0]\n",
    "    gc.collect()\n",
    "\n",
    "    # Length and indexes\n",
    "    anom_len = len(df_l1)  # total number of anomalous flows\n",
    "    anom_train_end = anom_len // 2  # 50% of anomalous for training\n",
    "    anom_cv_start = anom_train_end + 1  # 50% of anomalous for testing\n",
    "    norm_len = len(df_l0)  # total number of normal flows\n",
    "    norm_train_end = (norm_len * 60) // 100  # 60% of normal for training\n",
    "    norm_cv_start = norm_train_end + 1  # 20% of normal for cross validation\n",
    "    norm_cv_end = (norm_len * 80) // 100  # 20% of normal for cross validation\n",
    "    norm_test_start = norm_cv_end + 1  # 20% of normal for testing\n",
    "\n",
    "    # anomalies split data\n",
    "    anom_cv_df = df_l1[:anom_train_end]  # 50% of anomalies59452\n",
    "    anom_test_df = df_l1[anom_cv_start:anom_len]  # 50% of anomalies\n",
    "    gc.collect()\n",
    "\n",
    "    # normal split data\n",
    "    m_norm_train_df = df_l0[:norm_train_end]  # 60% of normal\n",
    "    norm_cv_df = df_l0[norm_cv_start:norm_cv_end]  # 20% of normal\n",
    "    norm_test_df = df_l0[norm_test_start:norm_len]  # 20% of normal\n",
    "    gc.collect()\n",
    "\n",
    "    # CV and test data. train data is norm_train_df\n",
    "    m_cv_df = pd.concat([norm_cv_df, anom_cv_df], axis=0)\n",
    "    m_test_df = pd.concat([norm_test_df, anom_test_df], axis=0)\n",
    "    gc.collect()\n",
    "\n",
    "    # Sort data by index\n",
    "    m_norm_train_df = m_norm_train_df.sort_index()\n",
    "    m_cv_df = m_cv_df.sort_index()\n",
    "    m_test_df = m_test_df.sort_index()\n",
    "    gc.collect()\n",
    "\n",
    "    # save labels and drop labels from data\n",
    "    m_cv_label = m_cv_df[\"Label\"]\n",
    "    m_test_label = m_test_df[\"Label\"]\n",
    "    m_norm_train_df = m_norm_train_df.drop(labels=[\"Label\"], axis=1)\n",
    "    m_cv_df = m_cv_df.drop(labels=[\"Label\"], axis=1)\n",
    "    m_test_df = m_test_df.drop(labels=[\"Label\"], axis=1)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return m_norm_train_df, m_cv_df, m_test_df, m_cv_label, m_test_label\n",
    "\n",
    "\n",
    "def getBestByNormalCV(t_normal, cv, t_cv_label):\n",
    "\n",
    "    # prepare data\n",
    "    m_cv_label = t_cv_label.astype(np.int8)\n",
    "    m_cv_label[m_cv_label == 1] = -1\n",
    "    m_cv_label[m_cv_label == 0] = 1\n",
    "\n",
    "    # initialize\n",
    "    m_best_model = MEllipticEnvelope()\n",
    "    m_best_contamination = 0\n",
    "    m_best_f1 = 0\n",
    "    m_best_precision = 0\n",
    "    m_best_recall = 0\n",
    "\n",
    "    m_contamination = 0.01\n",
    "    # configure GridSearchCV\n",
    "    m_ell_model = MEllipticEnvelope(contamination = m_contamination)\n",
    "    m_ell_model.fit(t_normal)\n",
    "    m_pred = m_ell_model.predict(cv)\n",
    "\n",
    "    m_f1 = f1_score(m_cv_label, m_pred, average=\"binary\")\n",
    "    m_recall = recall_score(m_cv_label, m_pred, average=\"binary\")\n",
    "    m_precision = precision_score(m_cv_label, m_pred, average=\"binary\")\n",
    "\n",
    "    if m_f1 > m_best_f1:\n",
    "        m_best_model = m_ell_model\n",
    "        m_best_contamination = m_contamination\n",
    "        m_best_f1 = m_f1\n",
    "        m_best_precision = m_precision\n",
    "        m_best_recall = m_recall\n",
    "\n",
    "    return m_best_model, m_best_contamination, m_best_f1, m_best_precision, m_best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl_fast/capture20110818-2.binetflow\n"
     ]
    }
   ],
   "source": [
    "column_types = {\n",
    "    'StartTime': 'str',\n",
    "    'Dur': 'float32',\n",
    "    'Proto': 'str',\n",
    "    'SrcAddr': 'str',\n",
    "    'Sport': 'str',\n",
    "    'Dir': 'str',\n",
    "    'DstAddr': 'str',\n",
    "    'Dport': 'str',\n",
    "    'State': 'str',\n",
    "    'sTos': 'float16',\n",
    "    'dTos': 'float16',\n",
    "    'TotPkts': 'uint32',\n",
    "    'TotBytes': 'uint32',\n",
    "    'SrcBytes': 'uint32',\n",
    "    'Label': 'uint8'}\n",
    "\n",
    "# feature selection\n",
    "drop_features = {\n",
    "    'drop_features01': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'TotBytes', 'Proto'],\n",
    "    'drop_features02': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'TotBytes'],\n",
    "    'drop_features03': ['SrcAddr', 'DstAddr', 'sTos', 'Sport', 'SrcBytes', 'Proto'],\n",
    "    'drop_features04': ['SrcAddr', 'DstAddr', 'sTos', 'Proto']\n",
    "}\n",
    "\n",
    "features_key = 'drop_features04'\n",
    "\n",
    "pkl_file_path = '/media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl_fast/capture20110818-2.binetflow'\n",
    "print(\"## Sample File: \", pkl_file_path)\n",
    "df = pd.read_pickle(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "norm_train_df, cv_df, test_df, cv_label, test_label = data_splitting(df, drop_features[features_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[EllipticEnvelope][ drop_features04 ] Cross-Validation. Contamination: 0.01 ,F1: 0.9022311068219939 , Recall: 0.9907650383528462 , Precision: 0.8282218941151656\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation and model selection\n",
    "ell_model, best_contamination, best_f1, best_precision, best_recall = getBestByNormalCV(norm_train_df, cv_df, cv_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Cross-Validation. Contamination:',best_contamination,',F1:', best_f1, ', Recall:', best_recall, ', Precision:', best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[EllipticEnvelope][ drop_features04 ] Test. F1: 0.90469097325664 , Recall: 0.9960639854670232 , Precision: 0.828673383711167\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_label = test_label.astype(np.int8)\n",
    "test_label[test_label == 1] = -1\n",
    "test_label[test_label == 0] = 1\n",
    "pred_test_label = ell_model.predict(test_df)\n",
    "\n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[EllipticEnvelope][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[skewness1][ drop_features04 ] Test. F1: 0.904716073147257 , Recall: 0.996114447191805 , Precision: 0.8286805759623861\n"
     ]
    }
   ],
   "source": [
    "# Prediction using skew1\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_skew1_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_skew1_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[skew1][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[skewness2][ drop_features04 ] Test. F1: 0.904716073147257 , Recall: 0.996114447191805 , Precision: 0.8286805759623861\n"
     ]
    }
   ],
   "source": [
    "# Prediction using skew2\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_skew2_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_skew2_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[skew2][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[kurtosis1][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using kurt1\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_kurt1_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_kurt1_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[kurt1][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[kurtosis2][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using kurt2\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_kurt2_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_kurt2_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[kurt][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[moment2][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using moment2\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_moment2_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_moment2_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[moment2][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[moment3][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using moment3\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_moment3_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_moment3_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[moment3][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[moment4][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using moment4\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_moment4_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_moment4_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[moment4][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[moment5][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using moment5\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_moment5_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.raw_moment5_dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[moment5][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###[moment6][ drop_features04 ] Test. F1: 0.0 , Recall: 0.0 , Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction using moment6\n",
    "is_inlier = np.full(test_df.shape[0], -1, dtype=int)\n",
    "mahal_dist = pairwise_distances(test_df, ell_model.raw_moment6_[np.newaxis, :], \n",
    "                          metric='mahalanobis', VI=linalg.pinvh(ell_model.covariance_))\n",
    "\n",
    "mahal_dist = np.reshape(mahal_dist, (len(test_df),)) ** 2\n",
    "mahal_dist = -mahal_dist\n",
    "dec_function = mahal_dist - (np.percentile(-ell_model.dist_, 100. * best_contamination))\n",
    "values = dec_function\n",
    "is_inlier[values >= 0] = 1\n",
    "pred_test_label = is_inlier\n",
    "    \n",
    "# print results\n",
    "f1, Recall, Precision = get_classification_report(test_label, pred_test_label)\n",
    "print('###[moment6][', features_key, '] Test. F1:', f1, ', Recall:', Recall, ', Precision:', Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

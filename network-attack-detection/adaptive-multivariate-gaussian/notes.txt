capture.binetflow
capture1.7.binetflow
capture1.binetflow
capture20110810.binetflow
capture20110811.binetflow
capture20110812.binetflow
capture20110815-2.binetflow
capture20110815-3.binetflow
capture20110815.binetflow
capture20110816-2.binetflow
capture20110816-3.binetflow
capture20110816.binetflow
capture20110817.binetflow
capture20110818-2.binetflow
capture20110818.binetflow
capture20110819.binetflow'
================================================================================================================================================================================================================================
    df.drop([
    #    'Dur',
        'Proto',
        'SrcAddr',
        'Sport',
    #    'Dir',
        'DstAddr',
    #    'Dport',
    #    'State',
        'sTos',
    #    'dTos',
    #    'TotPkts',
        'TotBytes',
        'SrcBytes'
    ], axis =1, inplace = True)

[MGM] Classification report for Cross Validation dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.90      0.94   3906387
          1       0.25      0.57      0.35    222346

avg / total       0.93      0.89      0.91   4128733

Average Precision = 0.1678114531035804

Binary F1 Score, Recall and Precision:
F1 Score 0.350998
Recall Score 0.571362
Precision Score 0.253303

[MGM] classification report for Test dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.92      0.95   3906394
          1       0.29      0.56      0.38    222340

avg / total       0.94      0.90      0.92   4128734

Average Precision = 0.18641272923408403

Binary F1 Score, Recall and Precision:
F1 Score 0.382992
Recall Score 0.557111
Precision Score 0.291795

[GMM] Classification report for Cross Validation dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.77      0.86   3906387
          1       0.14      0.64      0.22    222346

avg / total       0.93      0.76      0.83   4128733

Average Precision = 0.10562623699817737

Binary F1 Score, Recall and Precision:
F1 Score 0.223160
Recall Score 0.635231
Precision Score 0.135356

[GMM] Classification report for Test dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.92      0.95   3906394
          1       0.29      0.56      0.38    222340

avg / total       0.94      0.90      0.92   4128734

Average Precision = 0.18641272923408403

Binary F1 Score, Recall and Precision:
F1 Score 0.382992
Recall Score 0.557111
Precision Score 0.291795
CPU times: user 1h 48min 32s, sys: 1min 49s, total: 1h 50min 22s
Wall time: 1h 51min 30s
================================================================================================================================================================================================================================
    df.drop([
    #    'Dur',
    #    'Proto',
        'SrcAddr',
        'Sport',
    #    'Dir',
        'DstAddr',
    #    'Dport',
    #    'State',
        'sTos',
    #    'dTos',
    #    'TotPkts',
        'TotBytes',
        'SrcBytes'
    ], axis =1, inplace = True)

[MGM] Classification report for Cross Validation dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.90      0.94   3906387
          1       0.25      0.57      0.35    222346

avg / total       0.93      0.88      0.90   4128733

Average Precision = 0.16447985838822166

Binary F1 Score, Recall and Precision:
F1 Score 0.345354
Recall Score 0.571402
Precision Score 0.247459

[MGM] classification report for Test dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.92      0.95   3906394
          1       0.28      0.56      0.38    222340

avg / total       0.94      0.90      0.92   4128734

Average Precision = 0.18213877882826862

Binary F1 Score, Recall and Precision:
F1 Score 0.376319
Recall Score 0.557147
Precision Score 0.284109

[GMM] Classification report for Cross Validation dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.88      0.93   3906387
          1       0.23      0.59      0.33    222346

avg / total       0.93      0.87      0.89   4128733

Average Precision = 0.15522335043998917

Binary F1 Score, Recall and Precision:
F1 Score 0.326354
Recall Score 0.590737
Precision Score 0.225453

[GMM] Classification report for Test dataset
Classification report:
             precision    recall  f1-score   support

          0       0.97      0.92      0.95   3906394
          1       0.28      0.56      0.38    222340

avg / total       0.94      0.90      0.92   4128734

Average Precision = 0.18213877882826862

Binary F1 Score, Recall and Precision:
F1 Score 0.376319
Recall Score 0.557147
Precision Score 0.284109
CPU times: user 1h 34min 46s, sys: 1min 38s, total: 1h 36min 25s
Wall time: 1h 36min 19s
================================================================================================================================================================================================================================
    df.drop([
    #    'Dur',
        'Proto',
        'SrcAddr',
        'Sport',
    #    'Dir',
        'DstAddr',
    #    'Dport',
    #    'State',
        'sTos',
    #    'dTos',
    #    'TotPkts',
    #    'TotBytes',
        'SrcBytes'
    ], axis =1, inplace = True))

Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110817.binetflow
---------------------------------------------------------------------------
LinAlgError                               Traceback (most recent call last)
/usr/local/lib/python3.4/dist-packages/sklearn/mixture/gaussian_mixture.py in _compute_precision_cholesky(covariances, covariance_type)
    317             try:
--> 318                 cov_chol = linalg.cholesky(covariance, lower=True)
    319             except linalg.LinAlgError:

/usr/local/lib/python3.4/dist-packages/scipy/linalg/decomp_cholesky.py in cholesky(a, lower, overwrite_a, check_finite)
     80     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,
---> 81                             check_finite=check_finite)
     82     return c

/usr/local/lib/python3.4/dist-packages/scipy/linalg/decomp_cholesky.py in _cholesky(a, lower, overwrite_a, clean, check_finite)
     29     if info > 0:
---> 30         raise LinAlgError("%d-th leading minor not positive definite" % info)
     31     if info < 0:

LinAlgError: 7-th leading minor not positive definite

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<timed exec> in <module>()

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/base.py in fit(self, X, y)
    205 
    206             if do_init:
--> 207                 self._initialize_parameters(X, random_state)
    208                 self.lower_bound_ = -np.infty
    209 

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/base.py in _initialize_parameters(self, X, random_state)
    155                              % self.init_params)
    156 
--> 157         self._initialize(X, resp)
    158 
    159     @abstractmethod

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/gaussian_mixture.py in _initialize(self, X, resp)
    641             self.covariances_ = covariances
    642             self.precisions_cholesky_ = _compute_precision_cholesky(
--> 643                 covariances, self.covariance_type)
    644         elif self.covariance_type == 'full':
    645             self.precisions_cholesky_ = np.array(

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/gaussian_mixture.py in _compute_precision_cholesky(covariances, covariance_type)
    318                 cov_chol = linalg.cholesky(covariance, lower=True)
    319             except linalg.LinAlgError:
--> 320                 raise ValueError(estimate_precision_error_message)
    321             precisions_chol[k] = linalg.solve_triangular(cov_chol,
    322                                                          np.eye(n_features),

ValueError: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.
================================================================================================================================================================================================================================
    df.drop([
    #    'Dur',
        'Proto',
        'SrcAddr',
    #    'Sport',
    #    'Dir',
        'DstAddr',
    #    'Dport',
    #    'State',
        'sTos'
    #    'dTos',
    #    'TotPkts',
    #    'TotBytes',
    #    'SrcBytes'
    ], axis =1, inplace = True)

Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110810.binetflow
/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:338: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy

/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:

F-score is ill-defined and being set to 0.0 due to no predicted samples.

/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:

Precision is ill-defined and being set to 0.0 due to no predicted samples.


[MGM] Classification report for Cross Validation dataset
Classification report:
             precision    recall  f1-score   support

          0       1.00      0.82      0.90    556734
          1       0.16      0.96      0.28     20480

avg / total       0.97      0.82      0.88    577214

Average Precision = 0.1572097778377693

Binary F1 Score, Recall and Precision:
F1 Score 0.276900
Recall Score 0.964844
Precision Score 0.161645

[MGM] classification report for Test dataset
Classification report:
             precision    recall  f1-score   support

          0       1.00      0.87      0.93    556734
          1       0.22      0.98      0.36     20480

avg / total       0.97      0.87      0.91    577214

Average Precision = 0.21286545694060668

Binary F1 Score, Recall and Precision:
F1 Score 0.355491
Recall Score 0.975293
Precision Score 0.217359
---------------------------------------------------------------------------
LinAlgError                               Traceback (most recent call last)
/usr/local/lib/python3.4/dist-packages/sklearn/mixture/gaussian_mixture.py in _compute_precision_cholesky(covariances, covariance_type)
    317             try:
--> 318                 cov_chol = linalg.cholesky(covariance, lower=True)
    319             except linalg.LinAlgError:

/usr/local/lib/python3.4/dist-packages/scipy/linalg/decomp_cholesky.py in cholesky(a, lower, overwrite_a, check_finite)
     80     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,
---> 81                             check_finite=check_finite)
     82     return c

/usr/local/lib/python3.4/dist-packages/scipy/linalg/decomp_cholesky.py in _cholesky(a, lower, overwrite_a, clean, check_finite)
     29     if info > 0:
---> 30         raise LinAlgError("%d-th leading minor not positive definite" % info)
     31     if info < 0:

LinAlgError: 9-th leading minor not positive definite

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<timed exec> in <module>()

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/base.py in fit(self, X, y)
    205 
    206             if do_init:
--> 207                 self._initialize_parameters(X, random_state)
    208                 self.lower_bound_ = -np.infty
    209 

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/base.py in _initialize_parameters(self, X, random_state)
    155                              % self.init_params)
    156 
--> 157         self._initialize(X, resp)
    158 
    159     @abstractmethod

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/gaussian_mixture.py in _initialize(self, X, resp)
    641             self.covariances_ = covariances
    642             self.precisions_cholesky_ = _compute_precision_cholesky(
--> 643                 covariances, self.covariance_type)
    644         elif self.covariance_type == 'full':
    645             self.precisions_cholesky_ = np.array(

/usr/local/lib/python3.4/dist-packages/sklearn/mixture/gaussian_mixture.py in _compute_precision_cholesky(covariances, covariance_type)
    318                 cov_chol = linalg.cholesky(covariance, lower=True)
    319             except linalg.LinAlgError:
--> 320                 raise ValueError(estimate_precision_error_message)
    321             precisions_chol[k] = linalg.solve_triangular(cov_chol,
    322                                                          np.eye(n_features),

ValueError: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.

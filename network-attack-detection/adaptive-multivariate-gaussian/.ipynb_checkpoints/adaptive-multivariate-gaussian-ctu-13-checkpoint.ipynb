{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import ipaddress\n",
    "import random as rnd\n",
    "import plotly.graph_objs as go\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import itertools\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from functools import reduce\n",
    "from numpy import genfromtxt\n",
    "from scipy import linalg\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import preprocessing, mixture\n",
    "from sklearn.metrics import classification_report, average_precision_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleasing(df):\n",
    "    # data cleasing, feature engineering and save clean data into pickles\n",
    "    \n",
    "    print('Data Cleasing and Feature Engineering')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # [Protocol] - Discard ipv6-icmp and categorize\n",
    "    # df = df[df.Proto != 'ipv6-icmp']\n",
    "    df['Proto'] = df['Proto'].fillna('-')\n",
    "    df['Proto'] = le.fit_transform(df['Proto'])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "    # [Label] - Categorize \n",
    "    anomalies = df.Label.str.contains('Botnet')\n",
    "    normal = np.invert(anomalies);\n",
    "    df.loc[anomalies, 'Label'] = int(1)\n",
    "    df.loc[normal, 'Label'] = int(0)\n",
    "    df['Label'] = pd.to_numeric(df['Label'])\n",
    "\n",
    "    # [Dport] - replace NaN with 0 port number\n",
    "    df['Dport'] = df['Dport'].fillna('0')\n",
    "    df['Dport'] = df['Dport'].apply(lambda x: int(x,0))\n",
    "\n",
    "    # [sport] - replace NaN with 0 port number\n",
    "    df['Sport'] = df['Sport'].fillna('0')\n",
    "    df['Sport'] = df['Sport'].apply(lambda x: int(x,0))\n",
    "\n",
    "    # [sTos] - replace NaN with \"10\" and convert to int\n",
    "    df['sTos'] = df['sTos'].fillna('10')\n",
    "    df['sTos'] = df['sTos'].astype(int)\n",
    "\n",
    "    # [dTos] - replace NaN with \"10\" and convert to int\n",
    "    df['dTos'] = df['dTos'].fillna('10')\n",
    "    df['dTos'] = df['dTos'].astype(int)\n",
    "\n",
    "    # [State] - replace NaN with \"-\" and categorize\n",
    "    df['State'] = df['State'].fillna('-')\n",
    "    df['State'] = le.fit_transform(df['State'])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "    # [Dir] - replace NaN with \"-\" and categorize \n",
    "    df['Dir'] = df['Dir'].fillna('-')\n",
    "    df['Dir'] = le.fit_transform(df['Dir'])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "    # [SrcAddr] Extract subnet features and categorize\n",
    "    df['SrcAddr'] = df['SrcAddr'].fillna('0.0.0.0')\n",
    "    # tmp_df = pd.DataFrame(df['SrcAddr'].str.split('.').tolist(), columns = ['1','2','3','4'])\n",
    "    # df[\"SrcAddr1\"] = tmp_df[\"1\"]\n",
    "    # df[\"SrcAddr2\"] = tmp_df[\"1\"].map(str) + tmp_df[\"2\"]\n",
    "    # df[\"SrcAddr3\"] = tmp_df[\"1\"].map(str) + tmp_df[\"2\"].map(str) + tmp_df[\"3\"]\n",
    "    # df['SrcAddr0'] = le.fit_transform(df['SrcAddr'])\n",
    "    # le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    # df['SrcAddr1'] = df['SrcAddr1'].astype(int)\n",
    "    # df['SrcAddr2'] = df['SrcAddr2'].astype(int)\n",
    "    # df['SrcAddr3'] = df['SrcAddr3'].astype(int)\n",
    "\n",
    "    # [DstAddr] Extract subnet features\n",
    "    df['DstAddr'] = df['DstAddr'].fillna('0.0.0.0')\n",
    "    # tmp_df = pd.DataFrame(df['DstAddr'].str.split('.').tolist(), columns = ['1','2','3','4'])\n",
    "    # df[\"DstAddr1\"] = tmp_df[\"1\"]\n",
    "    # df[\"DstAddr2\"] = tmp_df[\"1\"].map(str) + tmp_df[\"2\"]\n",
    "    # df[\"DstAddr3\"] = tmp_df[\"1\"].map(str) + tmp_df[\"2\"].map(str) + tmp_df[\"3\"]\n",
    "    # df['DstAddr0'] = le.fit_transform(df['DstAddr'])\n",
    "    # df['DstAddr1'] = df['DstAddr1'].astype(int)\n",
    "    # df['DstAddr2'] = df['DstAddr2'].astype(int)\n",
    "    # df['DstAddr3'] = df['DstAddr3'].astype(int)\n",
    "\n",
    "    # [StartTime] - Parse to datatime, reindex based on StartTime, but first drop the ns off the time stamps\n",
    "    df['StartTime'] = df['StartTime'].apply(lambda x: x[:19])\n",
    "    df['StartTime'] = pd.to_datetime(df['StartTime'])\n",
    "    df = df.set_index('StartTime')\n",
    "\n",
    "    # save clean data into pickles\n",
    "    df.to_pickle(pkl_file_path)  # where to save it, usually as a .pkl\n",
    "    \n",
    "    return df\n",
    "\n",
    "def classify_ip(ip):\n",
    "    '''\n",
    "    str ip - ip address string to attempt to classify. treat ipv6 addresses as N/A\n",
    "    '''\n",
    "    try: \n",
    "        ip_addr = ipaddress.ip_address(ip)\n",
    "        if isinstance(ip_addr, ipaddress.IPv6Address):\n",
    "            return 'ipv6'\n",
    "        elif isinstance(ip_addr, ipaddress.IPv4Address):\n",
    "            # split on .\n",
    "            octs = ip_addr.exploded.split('.')\n",
    "            if 0 < int(octs[0]) < 127: return 'A'\n",
    "            elif 127 < int(octs[0]) < 192: return 'B'\n",
    "            elif 191 < int(octs[0]) < 224: return 'C'\n",
    "            else: return 'N/A'\n",
    "    except ValueError:\n",
    "        return 'N/A'\n",
    "    \n",
    "def avg_duration(x):\n",
    "    return np.average(x)\n",
    "    \n",
    "def n_dports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a,b: a+b if b>1024 else a),x)\n",
    "n_dports_gt1024.__name__ = 'n_dports>1024'\n",
    "\n",
    "def n_dports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a,b: a+b if b<1024 else a),x)\n",
    "n_dports_lt1024.__name__ = 'n_dports<1024'\n",
    "\n",
    "def n_sports_gt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a,b: a+b if b>1024 else a),x)\n",
    "n_sports_gt1024.__name__ = 'n_sports>1024'\n",
    "\n",
    "def n_sports_lt1024(x):\n",
    "    if x.size == 0: return 0\n",
    "    return reduce((lambda a,b: a+b if b<1024 else a),x)\n",
    "n_sports_lt1024.__name__ = 'n_sports<1024'\n",
    "\n",
    "def label_atk_v_norm(x):\n",
    "    for l in x:\n",
    "        if l == 1: return 1\n",
    "    return 0\n",
    "label_atk_v_norm.__name__ = 'label'\n",
    "\n",
    "def background_flow_count(x):\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "def normal_flow_count(x):\n",
    "    if x.size == 0: return 0\n",
    "    count = 0\n",
    "    for l in x:\n",
    "        if l == 0: count += 1\n",
    "    return count\n",
    "\n",
    "def n_conn(x):\n",
    "    return x.size\n",
    "\n",
    "def n_tcp(x):\n",
    "    count = 0\n",
    "    for p in x: \n",
    "        if p == 10: count += 1 # tcp == 10\n",
    "    return count\n",
    "    \n",
    "def n_udp(x):\n",
    "    count = 0\n",
    "    for p in x: \n",
    "        if p == 11: count += 1 # udp == 11\n",
    "    return count\n",
    "    \n",
    "def n_icmp(x):\n",
    "    count = 0\n",
    "    for p in x: \n",
    "        if p == 1: count += 1 # icmp == 1\n",
    "    return count\n",
    "\n",
    "def n_s_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "    \n",
    "def n_d_a_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "\n",
    "def n_s_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'B': count += 1\n",
    "    return count\n",
    "\n",
    "def n_d_b_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'A': count += 1\n",
    "    return count\n",
    "        \n",
    "def n_s_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "    \n",
    "def n_d_c_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'C': count += 1\n",
    "    return count\n",
    "        \n",
    "def n_s_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "    \n",
    "def n_d_na_p_address(x):\n",
    "    count = 0\n",
    "    for i in x: \n",
    "        if classify_ip(i) == 'N/A': count += 1\n",
    "    return count\n",
    "\n",
    "def n_ipv6(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if classify_ip(i) == 'ipv6': count += 1\n",
    "    return count\n",
    "\n",
    "def estimateGaussian(dataset):\n",
    "    mu = np.mean(dataset, axis=0)\n",
    "    sigma = np.cov(dataset.T)\n",
    "    return mu, sigma\n",
    "\n",
    "def multivariateGaussian(dataset, mu, sigma):\n",
    "    p = multivariate_normal(mean=mu, cov=sigma, allow_singular=True)\n",
    "    return p.pdf(dataset)\n",
    "\n",
    "def selectThresholdByCV(probs, labels):\n",
    "    # select best epsilon (threshold)\n",
    "    \n",
    "    # initialize\n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    \n",
    "#     farray = []\n",
    "#     Recallarray = []\n",
    "#     Precisionarray = []\n",
    "    min_prob = min(probs);\n",
    "    max_prob = max(probs);\n",
    "    stepsize = (max(probs) - min(probs)) / 1000;\n",
    "    epsilons = np.arange(min(probs), max(probs), stepsize)\n",
    "#     print('Epsilons min max: ',min(probs), max(probs))\n",
    "#     print('Epsilons: ', epsilons.size)\n",
    "#     print('Step Size: ', stepsize)\n",
    "    \n",
    "    for epsilon in epsilons:\n",
    "#         print('For below Epsilon: ', epsilon)\n",
    "        predictions = (probs < epsilon)\n",
    "        \n",
    "        f1 = f1_score(labels, predictions, average = \"binary\")\n",
    "        Recall = recall_score(labels, predictions, average = \"binary\")\n",
    "        Precision = precision_score(labels, predictions, average = \"binary\")    \n",
    "#         farray.append(f)\n",
    "#         Recallarray.append(Recall)\n",
    "#         Precisionarray.append(Precision)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_epsilon = epsilon\n",
    "            best_f1 = f1\n",
    "            best_precision = Precision\n",
    "            best_recall = Recall\n",
    "#             print('F1,Epsilon',best_f1,best_epsilon)\n",
    "            \n",
    "#             print('Best F1 Score: %f' %f)\n",
    "#             print('Best Recall Score: %f' %Recall)\n",
    "#             print('Best Precision Score: %f' %Precision)\n",
    "#             print('-'*40)\n",
    "\n",
    "#     # plot results\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_axes([0.1, 0.5, 0.7, 0.3])\n",
    "#     #plt.subplot(3,1,1)\n",
    "#     plt.plot(farray ,\"ro\")\n",
    "#     plt.plot(farray)\n",
    "#     ax.set_xticks(range(12))\n",
    "#     ax.set_xticklabels(epsilons,rotation = 60 ,fontsize = 'medium' )\n",
    "#     ax.set_ylim((0,1.1))\n",
    "#     ax.set_title('F1 score vs Epsilon value')\n",
    "#     ax.annotate('Best F1 Score', xy=(best_epsilon,best_f1), xytext=(best_epsilon,best_f1))\n",
    "#     plt.xlabel(\"Epsilon value\") \n",
    "#     plt.ylabel(\"F1 Score\") \n",
    "#     plt.show()\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_axes([0.1, 0.5, 0.9, 0.3])\n",
    "#     #plt.subplot(3,1,2)\n",
    "#     plt.plot(Recallarray ,\"ro\")\n",
    "#     plt.plot(Recallarray)\n",
    "#     ax.set_xticks(range(12))\n",
    "#     ax.set_xticklabels(epsilons,rotation = 60 ,fontsize = 'medium' )\n",
    "#     ax.set_ylim((0,1.1))\n",
    "#     ax.set_title('Recall vs Epsilon value')\n",
    "#     ax.annotate('Best Recall Score', xy=(best_epsilon, best_recall), xytext=(best_epsilon, best_recall))\n",
    "#     plt.xlabel(\"Epsilon value\") \n",
    "#     plt.ylabel(\"Recall Score\") \n",
    "#     plt.show()\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_axes([0.1, 0.5, 0.9, 0.3])\n",
    "#     #plt.subplot(3,1,3)\n",
    "#     plt.plot(Precisionarray ,\"ro\")\n",
    "#     plt.plot(Precisionarray)\n",
    "#     ax.set_xticks(range(12))\n",
    "#     ax.set_xticklabels(epsilons,rotation = 60 ,fontsize = 'medium' )\n",
    "#     ax.set_ylim((0,1.1))\n",
    "#     ax.set_title('Precision vs Epsilon value')\n",
    "#     ax.annotate('Best Precision Score', xy=(best_epsilon,best_precision), xytext=(best_epsilon,best_precision))\n",
    "#     plt.xlabel(\"Epsilon value\") \n",
    "#     plt.ylabel(\"Precision Score\") \n",
    "#     plt.show()\n",
    "\n",
    "    return best_f1, best_epsilon\n",
    "\n",
    "def print_classification_report(y_test, y_predic):\n",
    "    print('Classification report:')\n",
    "    print(classification_report(y_test, y_predic))\n",
    "\n",
    "    print('Average Precision = ' + str(average_precision_score(y_test, y_predic)))\n",
    "\n",
    "    print('\\nBinary F1 Score, Recall and Precision:')\n",
    "    f = f1_score(y_test, y_predic, average = \"binary\")\n",
    "    Recall = recall_score(y_test, y_predic, average = \"binary\")\n",
    "    Precision = precision_score(y_test, y_predic, average = \"binary\")\n",
    "    print('F1 Score %f' %f)\n",
    "    print('Recall Score %f' %Recall)\n",
    "    print('Precision Score %f' %Precision)\n",
    "\n",
    "#     print('\\nMicro F1 Score, Recall and Precision:')\n",
    "#     f = f1_score(y_test, y_predic, average = \"micro\")\n",
    "#     Recall = recall_score(y_test, y_predic, average = \"micro\")\n",
    "#     Precision = precision_score(y_test, y_predic, average = \"micro\")\n",
    "#     print('F1 Score %f' %f)\n",
    "#     print('Recall Score %f' %Recall)\n",
    "#     print('Precision Score %f' %Precision)\n",
    "\n",
    "#     print('\\nMacro F1 Score, Recall and Precision:')\n",
    "#     f = f1_score(y_test, y_predic, average = \"macro\")\n",
    "#     Recall = recall_score(y_test, y_predic, average = \"macro\")\n",
    "#     Precision = precision_score(y_test, y_predic, average = \"macro\")\n",
    "#     print('F1 Score %f' %f)\n",
    "#     print('Recall Score %f' %Recall)\n",
    "#     print('Precision Score %f' %Precision)\n",
    "\n",
    "def model_order_selection(data, max_components):\n",
    "    \n",
    "    bic = []\n",
    "    lowest_bic = np.infty\n",
    "    n_components_range = range(1, max_components)\n",
    "    cov_types = ['spherical', 'tied', 'diag', 'full']\n",
    "    \n",
    "    for cov_type in cov_types:\n",
    "        for n_components in n_components_range:\n",
    "            gmm = mixture.GaussianMixture(n_components=n_components, covariance_type=cov_type)\n",
    "            gmm.fit(data)\n",
    "            bic.append(gmm.bic(data))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "                best_n_components = n_components\n",
    "                best_cov_type = cov_type\n",
    "\n",
    "#     print('best_n_components:', best_n_components)\n",
    "#     print('best_cov_type:', best_cov_type)\n",
    "    \n",
    "    return best_n_components, best_cov_type\n",
    "\n",
    "def data_splitting(df):\n",
    "    # Data splitting\n",
    "    \n",
    "    # drop non discriminant features\n",
    "    df.drop([\n",
    "    #     'Dur',\n",
    "    #     'Proto',\n",
    "        'SrcAddr',\n",
    "        'Sport',\n",
    "    #     'Dir',\n",
    "        'DstAddr',\n",
    "    #     'Dport',\n",
    "    #     'State',\n",
    "        'sTos',\n",
    "    #     'dTos',\n",
    "    #     'TotPkts',\n",
    "        'TotBytes',\n",
    "        'SrcBytes'\n",
    "    ], axis =1, inplace = True)\n",
    "#     print(\"train_df_shape: \", df.shape)\n",
    "#     print('Train Data Types: ', df.dtypes)\n",
    "#     df.head()\n",
    "\n",
    "    # split into normal and anomaly\n",
    "    df_l1 = df[df[\"Label\"] == 1]\n",
    "    df_l0 = df[df[\"Label\"] == 0]\n",
    "\n",
    "#     print(\"df_l1_shape: \", df_l1.shape)\n",
    "#     print(\"df_l0_shape: \", df_l0.shape)\n",
    "\n",
    "    # Length and indexes\n",
    "    norm_len = len(df_l0)\n",
    "    anom_len = len(df_l1)\n",
    "    anom_train_end = anom_len // 2\n",
    "    anom_cv_start = anom_train_end + 1\n",
    "    norm_train_end = (norm_len * 60) // 100\n",
    "    norm_cv_start = norm_train_end + 1\n",
    "    norm_cv_end = (norm_len * 80) // 100\n",
    "    norm_test_start = norm_cv_end + 1\n",
    "\n",
    "    # anomalies split data\n",
    "    anom_cv_df  = df_l1[:anom_train_end] # 50% of anomalies59452 \n",
    "    anom_test_df = df_l1[anom_cv_start:anom_len] # 50% of anomalies\n",
    "\n",
    "    # normal split data\n",
    "    norm_train_df = df_l0[:norm_train_end] # 60% of normal\n",
    "    norm_cv_df = df_l0[norm_cv_start:norm_cv_end] # 2059452 % of normal\n",
    "    norm_test_df = df_l0 [norm_test_start:norm_len] # 20% of normal\n",
    "\n",
    "    # CV and test data. train data is norm_train_df\n",
    "    cv_df = pd.concat([norm_cv_df, anom_cv_df], axis=0)\n",
    "    test_df = pd.concat([norm_test_df, anom_test_df], axis=0)\n",
    "\n",
    "    # labels\n",
    "    cv_label = cv_df[\"Label\"]\n",
    "    test_label = test_df[\"Label\"]\n",
    "\n",
    "    # drop label\n",
    "    norm_train_df.drop(labels = [\"Label\"], axis = 1, inplace = True)\n",
    "    cv_df.drop(labels = [\"Label\"], axis = 1, inplace = True)\n",
    "    test_df.drop(labels = [\"Label\"], axis = 1, inplace = True)\n",
    "\n",
    "#     print(\"norm_train_df_shape: \", norm_train_df.shape)\n",
    "#     print(\"cv_shape: \", cv_df.shape)\n",
    "#     print(\"test_df_shape: \", test_df.shape)\n",
    "    \n",
    "    return norm_train_df, cv_df, test_df, cv_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory:  b'/media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/raw/'\n",
      "Files:  [b'capture20110810.binetflow', b'capture20110811.binetflow', b'capture20110812.binetflow', b'capture20110815-2.binetflow', b'capture20110815-3.binetflow', b'capture20110815.binetflow', b'capture20110816-2.binetflow', b'capture20110816-3.binetflow', b'capture20110816.binetflow', b'capture20110817.binetflow', b'capture20110818-2.binetflow', b'capture20110818.binetflow', b'capture20110819.binetflow']\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110810.binetflow\n",
      "train_df_shape:  (2824636, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (40961, 8)\n",
      "df_l0_shape:  (2783675, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:420: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_train_df_shape:  (1670205, 7)\n",
      "cv_shape:  (577214, 7)\n",
      "test_df_shape:  (577214, 7)\n",
      "Epsilons min max:  0.0 1.4863553196534992e-16\n",
      "Epsilons:  1000\n",
      "Step Size:  1.4863553196534993e-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epsilon:  3.2699817032376983e-18\n",
      "Best F1_score:  0.18672661804755897\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96    556734\n",
      "          1       0.15      0.25      0.19     20480\n",
      "\n",
      "avg / total       0.94      0.92      0.93    577214\n",
      "\n",
      "Average Precision = 0.06384930271546099\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.186727\n",
      "Recall Score 0.249414\n",
      "Precision Score 0.149221\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96    556734\n",
      "          1       0.16      0.24      0.19     20480\n",
      "\n",
      "avg / total       0.94      0.93      0.93    577214\n",
      "\n",
      "Average Precision = 0.0649116739432053\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.190671\n",
      "Recall Score 0.239307\n",
      "Precision Score 0.158465\n",
      "Epsilons min max:  -3538.00599057566 37.745334849985255\n",
      "Epsilons:  1000\n",
      "Step Size:  3.575751325425645\n",
      "Best epsilon:  -12.31518370592039\n",
      "Best F1_score:  0.1375055920510466\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.89      0.93    556734\n",
      "          1       0.09      0.29      0.14     20480\n",
      "\n",
      "avg / total       0.94      0.87      0.90    577214\n",
      "\n",
      "Average Precision = 0.051197228670061684\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.137506\n",
      "Recall Score 0.285156\n",
      "Precision Score 0.090596\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.89      0.93    556734\n",
      "          1       0.09      0.29      0.14     20480\n",
      "\n",
      "avg / total       0.94      0.87      0.90    577214\n",
      "\n",
      "Average Precision = 0.051436630364211894\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.137680\n",
      "Recall Score 0.292529\n",
      "Precision Score 0.090025\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110811.binetflow\n",
      "train_df_shape:  (1808122, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (20941, 8)\n",
      "df_l0_shape:  (1787181, 8)\n",
      "norm_train_df_shape:  (1072308, 7)\n",
      "cv_shape:  (367905, 7)\n",
      "test_df_shape:  (367906, 7)\n",
      "Epsilons min max:  0.0 1.364992945424523e-16\n",
      "Epsilons:  1000\n",
      "Step Size:  1.364992945424523e-19\n",
      "Best epsilon:  1.364992945424523e-19\n",
      "Best F1_score:  0.5181591961445176\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.96      0.98    357435\n",
      "          1       0.39      0.79      0.52     10470\n",
      "\n",
      "avg / total       0.98      0.96      0.97    367905\n",
      "\n",
      "Average Precision = 0.30978110291200034\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.518159\n",
      "Recall Score 0.785578\n",
      "Precision Score 0.386568\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.96      0.98    357436\n",
      "          1       0.35      0.67      0.46     10470\n",
      "\n",
      "avg / total       0.97      0.96      0.96    367906\n",
      "\n",
      "Average Precision = 0.24710755765652062\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.463841\n",
      "Recall Score 0.670487\n",
      "Precision Score 0.354563\n",
      "Epsilons min max:  -428476715.6743252 37.792771011759186\n",
      "Epsilons:  1000\n",
      "Step Size:  428476.75346709625\n",
      "Best epsilon:  0\n",
      "Best F1_score:  0\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.67      0.80    357435\n",
      "          1       0.07      0.83      0.13     10470\n",
      "\n",
      "avg / total       0.97      0.68      0.78    367905\n",
      "\n",
      "Average Precision = 0.061809275930941855\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.126999\n",
      "Recall Score 0.827125\n",
      "Precision Score 0.068780\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.48      0.64    357436\n",
      "          1       0.04      0.70      0.07     10470\n",
      "\n",
      "avg / total       0.96      0.49      0.63    367906\n",
      "\n",
      "Average Precision = 0.03506838408370859\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.071913\n",
      "Recall Score 0.699809\n",
      "Precision Score 0.037904\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110812.binetflow\n",
      "train_df_shape:  (4710638, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (26822, 8)\n",
      "df_l0_shape:  (4683816, 8)\n",
      "norm_train_df_shape:  (2810289, 7)\n",
      "cv_shape:  (950173, 7)\n",
      "test_df_shape:  (950173, 7)\n",
      "Epsilons min max:  0.0 3.1662595287094697e-16\n",
      "Epsilons:  1000\n",
      "Step Size:  3.1662595287094695e-19\n",
      "Best epsilon:  4.306112959044879e-17\n",
      "Best F1_score:  0.14224220446428082\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91    936762\n",
      "          1       0.08      0.97      0.14     13411\n",
      "\n",
      "avg / total       0.99      0.83      0.90    950173\n",
      "\n",
      "Average Precision = 0.07484541089001528\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.142242\n",
      "Recall Score 0.969577\n",
      "Precision Score 0.076751\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93    936763\n",
      "          1       0.10      0.99      0.18     13410\n",
      "\n",
      "avg / total       0.99      0.87      0.92    950173\n",
      "\n",
      "Average Precision = 0.09960712223375336\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.182068\n",
      "Recall Score 0.992841\n",
      "Precision Score 0.100224\n",
      "Epsilons min max:  -6290.135490731407 31.072345806363856\n",
      "Epsilons:  1000\n",
      "Step Size:  6.321207836537771\n",
      "Best epsilon:  -25.818524722522852\n",
      "Best F1_score:  0.10384250241799972\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88    936762\n",
      "          1       0.06      0.87      0.10     13411\n",
      "\n",
      "avg / total       0.98      0.79      0.87    950173\n",
      "\n",
      "Average Precision = 0.049821195767161916\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.103843\n",
      "Recall Score 0.868615\n",
      "Precision Score 0.055222\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88    936763\n",
      "          1       0.06      0.95      0.11     13410\n",
      "\n",
      "avg / total       0.99      0.79      0.87    950173\n",
      "\n",
      "Average Precision = 0.056553105459118444\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.111011\n",
      "Recall Score 0.946234\n",
      "Precision Score 0.058965\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110815-2.binetflow\n",
      "train_df_shape:  (129832, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (901, 8)\n",
      "df_l0_shape:  (128931, 8)\n",
      "norm_train_df_shape:  (77358, 7)\n",
      "cv_shape:  (26235, 7)\n",
      "test_df_shape:  (26236, 7)\n",
      "Epsilons min max:  1.1387621329596767e-188 1.560349340169487e-15\n",
      "Epsilons:  1000\n",
      "Step Size:  1.5603493401694871e-18\n",
      "Best epsilon:  1.5603493401694871e-18\n",
      "Best F1_score:  0.17693631669535284\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95     25785\n",
      "          1       0.10      0.57      0.18       450\n",
      "\n",
      "avg / total       0.98      0.91      0.94     26235\n",
      "\n",
      "Average Precision = 0.06714296172344822\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.176936\n",
      "Recall Score 0.571111\n",
      "Precision Score 0.104684\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95     25786\n",
      "          1       0.14      0.82      0.24       450\n",
      "\n",
      "avg / total       0.98      0.91      0.94     26236\n",
      "\n",
      "Average Precision = 0.11615910975710642\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.236084\n",
      "Recall Score 0.820000\n",
      "Precision Score 0.137892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilons min max:  -131.28044713510715 22.65596562220633\n",
      "Epsilons:  1000\n",
      "Step Size:  0.15393641275731348\n",
      "Best epsilon:  -39.38040871899682\n",
      "Best F1_score:  0.3504531722054381\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     25785\n",
      "          1       0.55      0.26      0.35       450\n",
      "\n",
      "avg / total       0.98      0.98      0.98     26235\n",
      "\n",
      "Average Precision = 0.15377930245854773\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.350453\n",
      "Recall Score 0.257778\n",
      "Precision Score 0.547170\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     25786\n",
      "          1       0.35      0.14      0.20       450\n",
      "\n",
      "avg / total       0.97      0.98      0.98     26236\n",
      "\n",
      "Average Precision = 0.06360153817485728\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.198400\n",
      "Recall Score 0.137778\n",
      "Precision Score 0.354286\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110815-3.binetflow\n",
      "train_df_shape:  (1925149, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (40003, 8)\n",
      "df_l0_shape:  (1885146, 8)\n",
      "norm_train_df_shape:  (1131087, 7)\n",
      "cv_shape:  (397029, 7)\n",
      "test_df_shape:  (397030, 7)\n",
      "Epsilons min max:  0.0 6.212312420583777e-16\n",
      "Epsilons:  1000\n",
      "Step Size:  6.212312420583778e-19\n",
      "Best epsilon:  6.212312420583778e-19\n",
      "Best F1_score:  0.309421672398498\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.87      0.92    377028\n",
      "          1       0.20      0.64      0.31     20001\n",
      "\n",
      "avg / total       0.94      0.86      0.89    397029\n",
      "\n",
      "Average Precision = 0.1484085016880618\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.309422\n",
      "Recall Score 0.636518\n",
      "Precision Score 0.204389\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.93    377029\n",
      "          1       0.28      0.91      0.43     20001\n",
      "\n",
      "avg / total       0.96      0.88      0.91    397030\n",
      "\n",
      "Average Precision = 0.25934149120994243\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.429093\n",
      "Recall Score 0.905405\n",
      "Precision Score 0.281174\n",
      "Epsilons min max:  -467.153391216272 40.94092014009199\n",
      "Epsilons:  1000\n",
      "Step Size:  0.508094311356364\n",
      "Best epsilon:  -8.344228061453975\n",
      "Best F1_score:  0.2771176820368669\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.84      0.90    377028\n",
      "          1       0.18      0.64      0.28     20001\n",
      "\n",
      "avg / total       0.94      0.83      0.87    397029\n",
      "\n",
      "Average Precision = 0.131376388941624\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.277118\n",
      "Recall Score 0.640768\n",
      "Precision Score 0.176787\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.84      0.91    377029\n",
      "          1       0.22      0.87      0.36     20001\n",
      "\n",
      "avg / total       0.95      0.84      0.88    397030\n",
      "\n",
      "Average Precision = 0.20142957351522936\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.356127\n",
      "Recall Score 0.870856\n",
      "Precision Score 0.223830\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110815.binetflow\n",
      "train_df_shape:  (1121076, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (2580, 8)\n",
      "df_l0_shape:  (1118496, 8)\n",
      "norm_train_df_shape:  (671097, 7)\n",
      "cv_shape:  (224988, 7)\n",
      "test_df_shape:  (224988, 7)\n",
      "Epsilons min max:  0.0 6.589101753668418e-17\n",
      "Epsilons:  1000\n",
      "Step Size:  6.589101753668418e-20\n",
      "Best epsilon:  5.271281402934734e-19\n",
      "Best F1_score:  0.05608795343641602\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96    223698\n",
      "          1       0.03      0.37      0.06      1290\n",
      "\n",
      "avg / total       0.99      0.93      0.96    224988\n",
      "\n",
      "Average Precision = 0.014834282449369008\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.056088\n",
      "Recall Score 0.369767\n",
      "Precision Score 0.030345\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99    223699\n",
      "          1       0.01      0.04      0.02      1289\n",
      "\n",
      "avg / total       0.99      0.98      0.98    224988\n",
      "\n",
      "Average Precision = 0.005986615932672031\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.018936\n",
      "Recall Score 0.036462\n",
      "Precision Score 0.012789\n",
      "Epsilons min max:  -2771.530226276832 28.54072265694871\n",
      "Epsilons:  1000\n",
      "Step Size:  2.8000709489337807\n",
      "Best epsilon:  -35.86090916850162\n",
      "Best F1_score:  0.1854931559421773\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99    223698\n",
      "          1       0.11      0.56      0.19      1290\n",
      "\n",
      "avg / total       0.99      0.97      0.98    224988\n",
      "\n",
      "Average Precision = 0.06493827741894304\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.185493\n",
      "Recall Score 0.562016\n",
      "Precision Score 0.111077\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99    223699\n",
      "          1       0.18      0.94      0.31      1289\n",
      "\n",
      "avg / total       0.99      0.98      0.98    224988\n",
      "\n",
      "Average Precision = 0.17417611345722317\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.308670\n",
      "Recall Score 0.941815\n",
      "Precision Score 0.184583\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110816-2.binetflow\n",
      "train_df_shape:  (114077, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (63, 8)\n",
      "df_l0_shape:  (114014, 8)\n",
      "norm_train_df_shape:  (68408, 7)\n",
      "cv_shape:  (22833, 7)\n",
      "test_df_shape:  (22833, 7)\n",
      "Epsilons min max:  0.0 1.5868494912307712e-15\n",
      "Epsilons:  1000\n",
      "Step Size:  1.5868494912307712e-18\n",
      "Best epsilon:  1.269479592984617e-17\n",
      "Best F1_score:  0.01048951048951049\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93     22802\n",
      "          1       0.01      0.48      0.01        31\n",
      "\n",
      "avg / total       1.00      0.88      0.93     22833\n",
      "\n",
      "Average Precision = 0.0032663338351677867\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.010490\n",
      "Recall Score 0.483871\n",
      "Precision Score 0.005302\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93     22802\n",
      "          1       0.01      0.58      0.01        31\n",
      "\n",
      "avg / total       1.00      0.87      0.93     22833\n",
      "\n",
      "Average Precision = 0.004095536567414573\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.012020\n",
      "Recall Score 0.580645\n",
      "Precision Score 0.006073\n",
      "Epsilons min max:  -396.25488961560046 20.20912118129648\n",
      "Epsilons:  1001\n",
      "Step Size:  0.41646401079689693\n",
      "Best epsilon:  -25.18545599554932\n",
      "Best F1_score:  0.01867704280155642\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     22802\n",
      "          1       0.01      0.39      0.02        31\n",
      "\n",
      "avg / total       1.00      0.94      0.97     22833\n",
      "\n",
      "Average Precision = 0.004536404287323283\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.018677\n",
      "Recall Score 0.387097\n",
      "Precision Score 0.009569\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97     22802\n",
      "          1       0.01      0.52      0.02        31\n",
      "\n",
      "avg / total       1.00      0.94      0.97     22833\n",
      "\n",
      "Average Precision = 0.0070338276932298315\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.024133\n",
      "Recall Score 0.516129\n",
      "Precision Score 0.012355\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110816-3.binetflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_shape:  (2954230, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (6127, 8)\n",
      "df_l0_shape:  (2948103, 8)\n",
      "norm_train_df_shape:  (1768861, 7)\n",
      "cv_shape:  (592683, 7)\n",
      "test_df_shape:  (592683, 7)\n",
      "Epsilons min max:  0.0 2.816970336771637e-16\n",
      "Epsilons:  1001\n",
      "Step Size:  2.816970336771637e-19\n",
      "Best epsilon:  2.816970336771637e-19\n",
      "Best F1_score:  0.06207408406990082\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94    589620\n",
      "          1       0.03      0.75      0.06      3063\n",
      "\n",
      "avg / total       0.99      0.88      0.93    592683\n",
      "\n",
      "Average Precision = 0.025597843968238547\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.062074\n",
      "Recall Score 0.750898\n",
      "Precision Score 0.032375\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94    589620\n",
      "          1       0.04      0.80      0.07      3063\n",
      "\n",
      "avg / total       0.99      0.89      0.94    592683\n",
      "\n",
      "Average Precision = 0.029424901283810354\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.068188\n",
      "Recall Score 0.796605\n",
      "Precision Score 0.035618\n",
      "Epsilons min max:  -19925.37541622158 39.52070777891716\n",
      "Epsilons:  1000\n",
      "Step Size:  19.964896124000497\n",
      "Best epsilon:  -20.37398059176121\n",
      "Best F1_score:  0.10409459163564704\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96    589620\n",
      "          1       0.06      0.78      0.10      3063\n",
      "\n",
      "avg / total       0.99      0.93      0.96    592683\n",
      "\n",
      "Average Precision = 0.04445171734196031\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.104095\n",
      "Recall Score 0.776037\n",
      "Precision Score 0.055789\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.97    589620\n",
      "          1       0.06      0.80      0.11      3063\n",
      "\n",
      "avg / total       0.99      0.93      0.96    592683\n",
      "\n",
      "Average Precision = 0.0485434020367431\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.110934\n",
      "Recall Score 0.796605\n",
      "Precision Score 0.059618\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110816.binetflow\n",
      "train_df_shape:  (558919, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (4630, 8)\n",
      "df_l0_shape:  (554289, 8)\n",
      "norm_train_df_shape:  (332573, 7)\n",
      "cv_shape:  (113172, 7)\n",
      "test_df_shape:  (113171, 7)\n",
      "Epsilons min max:  3.326981014203259e-170 7.342234349054252e-17\n",
      "Epsilons:  1001\n",
      "Step Size:  7.342234349054251e-20\n",
      "Best epsilon:  4.4053406094325505e-19\n",
      "Best F1_score:  0.6090820719344535\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99    110857\n",
      "          1       0.45      0.95      0.61      2315\n",
      "\n",
      "avg / total       0.99      0.98      0.98    113172\n",
      "\n",
      "Average Precision = 0.42625798339403814\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.609082\n",
      "Recall Score 0.947300\n",
      "Precision Score 0.448833\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99    110857\n",
      "          1       0.46      0.95      0.62      2314\n",
      "\n",
      "avg / total       0.99      0.98      0.98    113171\n",
      "\n",
      "Average Precision = 0.44140324749679877\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.622304\n",
      "Recall Score 0.953760\n",
      "Precision Score 0.461812\n",
      "Epsilons min max:  -148.54496783444756 37.62584219714015\n",
      "Epsilons:  1000\n",
      "Step Size:  0.1861708100315877\n",
      "Best epsilon:  -13.384959751507438\n",
      "Best F1_score:  0.31144518508013047\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95    110857\n",
      "          1       0.19      0.95      0.31      2315\n",
      "\n",
      "avg / total       0.98      0.91      0.94    113172\n",
      "\n",
      "Average Precision = 0.17778154372180016\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.311445\n",
      "Recall Score 0.948596\n",
      "Precision Score 0.186307\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95    110857\n",
      "          1       0.18      0.95      0.30      2314\n",
      "\n",
      "avg / total       0.98      0.91      0.94    113171\n",
      "\n",
      "Average Precision = 0.172910814242334\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.303193\n",
      "Recall Score 0.954192\n",
      "Precision Score 0.180230\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110817.binetflow\n",
      "train_df_shape:  (2087508, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (184987, 8)\n",
      "df_l0_shape:  (1902521, 8)\n",
      "norm_train_df_shape:  (1141512, 7)\n",
      "cv_shape:  (472996, 7)\n",
      "test_df_shape:  (472997, 7)\n",
      "Epsilons min max:  0.0 6.75990313465751e-17\n",
      "Epsilons:  1000\n",
      "Step Size:  6.759903134657509e-20\n",
      "Best epsilon:  4.731932194260257e-19\n",
      "Best F1_score:  0.46568805291212007\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90    380503\n",
      "          1       0.66      0.36      0.47     92493\n",
      "\n",
      "avg / total       0.82      0.84      0.82    472996\n",
      "\n",
      "Average Precision = 0.36185869803264537\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.465688\n",
      "Recall Score 0.360827\n",
      "Precision Score 0.656465\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91    380504\n",
      "          1       0.73      0.30      0.42     92493\n",
      "\n",
      "avg / total       0.83      0.84      0.81    472997\n",
      "\n",
      "Average Precision = 0.3543937429566447\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.422035\n",
      "Recall Score 0.296649\n",
      "Precision Score 0.731017\n",
      "Epsilons min max:  -13013.561405638136 4.937537191480871\n",
      "Epsilons:  1000\n",
      "Step Size:  13.018498942829618\n",
      "Best epsilon:  -8.080961752009898\n",
      "Best F1_score:  0.38204638000496854\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.85      0.85    380503\n",
      "          1       0.38      0.38      0.38     92493\n",
      "\n",
      "avg / total       0.76      0.76      0.76    472996\n",
      "\n",
      "Average Precision = 0.26672592337921575\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.382046\n",
      "Recall Score 0.382418\n",
      "Precision Score 0.381675\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.78      0.80    380504\n",
      "          1       0.26      0.31      0.28     92493\n",
      "\n",
      "avg / total       0.71      0.69      0.70    472997\n",
      "\n",
      "Average Precision = 0.21494678152656738\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.281373\n",
      "Recall Score 0.308899\n",
      "Precision Score 0.258351\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110818-2.binetflow\n",
      "train_df_shape:  (107251, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (8164, 8)\n",
      "df_l0_shape:  (99087, 8)\n",
      "norm_train_df_shape:  (59452, 7)\n",
      "cv_shape:  (23898, 7)\n",
      "test_df_shape:  (23898, 7)\n",
      "Epsilons min max:  2.3419627877432367e-35 1.2884208055572452e-15\n",
      "Epsilons:  1000\n",
      "Step Size:  1.2884208055572452e-18\n",
      "Best epsilon:  1.2884208055572452e-18\n",
      "Best F1_score:  0.7692598902138935\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93     19816\n",
      "          1       0.63      1.00      0.77      4082\n",
      "\n",
      "avg / total       0.94      0.90      0.91     23898\n",
      "\n",
      "Average Precision = 0.6247629748333259\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.769260\n",
      "Recall Score 0.995590\n",
      "Precision Score 0.626774\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89     19817\n",
      "          1       0.51      1.00      0.67      4081\n",
      "\n",
      "avg / total       0.92      0.83      0.85     23898\n",
      "\n",
      "Average Precision = 0.5059509050334738\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.671935\n",
      "Recall Score 1.000000\n",
      "Precision Score 0.505951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilons min max:  -19476.59521266137 28.290046571653626\n",
      "Epsilons:  1001\n",
      "Step Size:  19.50488525923302\n",
      "Best epsilon:  -30.224609205510205\n",
      "Best F1_score:  0.8673643741990602\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97     19816\n",
      "          1       0.77      0.99      0.87      4082\n",
      "\n",
      "avg / total       0.96      0.95      0.95     23898\n",
      "\n",
      "Average Precision = 0.7657609828759921\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.867364\n",
      "Recall Score 0.994855\n",
      "Precision Score 0.768838\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94     19817\n",
      "          1       0.65      1.00      0.78      4081\n",
      "\n",
      "avg / total       0.94      0.91      0.91     23898\n",
      "\n",
      "Average Precision = 0.6459322570433682\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.784883\n",
      "Recall Score 1.000000\n",
      "Precision Score 0.645932\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110818.binetflow\n",
      "train_df_shape:  (1309791, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (106352, 8)\n",
      "df_l0_shape:  (1203439, 8)\n",
      "norm_train_df_shape:  (722063, 7)\n",
      "cv_shape:  (293863, 7)\n",
      "test_df_shape:  (293862, 7)\n",
      "Epsilons min max:  0.0 5.005412150972549e-17\n",
      "Epsilons:  1000\n",
      "Step Size:  5.0054121509725487e-20\n",
      "Best epsilon:  8.008659441556078e-19\n",
      "Best F1_score:  0.7877239653987773\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.94      0.95    240687\n",
      "          1       0.74      0.84      0.79     53176\n",
      "\n",
      "avg / total       0.92      0.92      0.92    293863\n",
      "\n",
      "Average Precision = 0.6517967882668717\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.787724\n",
      "Recall Score 0.840830\n",
      "Precision Score 0.740927\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97    240687\n",
      "          1       0.92      0.81      0.87     53175\n",
      "\n",
      "avg / total       0.95      0.95      0.95    293862\n",
      "\n",
      "Average Precision = 0.7861135755445543\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.865743\n",
      "Recall Score 0.814311\n",
      "Precision Score 0.924110\n",
      "Epsilons min max:  -12295.619278571456 9.068265111174794\n",
      "Epsilons:  1000\n",
      "Step Size:  12.30468754368263\n",
      "Best epsilon:  -40.15048506315725\n",
      "Best F1_score:  0.9714942317415085\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99    240687\n",
      "          1       0.95      0.99      0.97     53176\n",
      "\n",
      "avg / total       0.99      0.99      0.99    293863\n",
      "\n",
      "Average Precision = 0.9454099546185541\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.971494\n",
      "Recall Score 0.993719\n",
      "Precision Score 0.950242\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99    240687\n",
      "          1       0.94      0.99      0.96     53175\n",
      "\n",
      "avg / total       0.99      0.99      0.99    293862\n",
      "\n",
      "Average Precision = 0.9320713021737166\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.964389\n",
      "Recall Score 0.993117\n",
      "Precision Score 0.937277\n",
      "Sample File:  /media/thiago/ubuntu/datasets/network/stratosphere-botnet-2011/ctu-13/pkl/capture20110819.binetflow\n",
      "train_df_shape:  (325471, 8)\n",
      "Train Data Types:  Dur        float64\n",
      "Proto        int64\n",
      "Dir          int64\n",
      "Dport        int64\n",
      "State        int64\n",
      "dTos         int64\n",
      "TotPkts      int64\n",
      "Label        int64\n",
      "dtype: object\n",
      "df_l1_shape:  (2168, 8)\n",
      "df_l0_shape:  (323303, 8)\n",
      "norm_train_df_shape:  (193981, 7)\n",
      "cv_shape:  (65744, 7)\n",
      "test_df_shape:  (65743, 7)\n",
      "Epsilons min max:  0.0 3.60345850756061e-16\n",
      "Epsilons:  1000\n",
      "Step Size:  3.60345850756061e-19\n",
      "Best epsilon:  1.9819021791583353e-17\n",
      "Best F1_score:  0.09302325581395349\n",
      "[MGM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.83      0.90     64660\n",
      "          1       0.05      0.54      0.09      1084\n",
      "\n",
      "avg / total       0.98      0.83      0.89     65744\n",
      "\n",
      "Average Precision = 0.03519483681134652\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.093023\n",
      "Recall Score 0.544280\n",
      "Precision Score 0.050858\n",
      "[MGM] classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.81      0.89     64660\n",
      "          1       0.05      0.58      0.09      1083\n",
      "\n",
      "avg / total       0.98      0.81      0.88     65743\n",
      "\n",
      "Average Precision = 0.03518623409729959\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.089701\n",
      "Recall Score 0.582641\n",
      "Precision Score 0.048591\n",
      "Epsilons min max:  -2016.874467770222 4.902465365951051\n",
      "Epsilons:  1000\n",
      "Step Size:  2.0217769331361732\n",
      "Best epsilon:  -11.271750099158908\n",
      "Best F1_score:  0.09348530795775385\n",
      "[GMM] Classification report for Cross Validation dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.93     64660\n",
      "          1       0.05      0.41      0.09      1084\n",
      "\n",
      "avg / total       0.97      0.87      0.92     65744\n",
      "\n",
      "Average Precision = 0.031428175504255244\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.093485\n",
      "Recall Score 0.412362\n",
      "Precision Score 0.052718\n",
      "[GMM] Classification report for Test dataset\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.92     64660\n",
      "          1       0.04      0.33      0.07      1083\n",
      "\n",
      "avg / total       0.97      0.85      0.90     65743\n",
      "\n",
      "Average Precision = 0.02305376220085651\n",
      "\n",
      "Binary F1 Score, Recall and Precision:\n",
      "F1 Score 0.065619\n",
      "Recall Score 0.329640\n",
      "Precision Score 0.036436\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_path = os.path.join('/media/thiago/ubuntu/datasets/network/','stratosphere-botnet-2011/ctu-13/raw/')\n",
    "raw_directory = os.fsencode(raw_path)\n",
    "raw_files = os.listdir(raw_directory)\n",
    "print(\"Directory: \", raw_directory)\n",
    "print(\"Files: \", raw_files)\n",
    "\n",
    "# pickle files have the same names\n",
    "pkl_path = os.path.join('/media/thiago/ubuntu/datasets/network/','stratosphere-botnet-2011/ctu-13/pkl/')\n",
    "pkl_directory = os.fsencode(pkl_path)\n",
    "\n",
    "mgm_cv_label = []\n",
    "mgm_pred_cv_label = []\n",
    "mgm_test_label = []\n",
    "mgm_pred_test_label = []\n",
    "gmm_cv_label = []\n",
    "gmm_pred_cv_label = []\n",
    "gmm_test_label = []\n",
    "gmm_pred_test_label = []\n",
    "\n",
    "for sample_file in raw_files:\n",
    "    pkl_file_path = os.path.join(pkl_directory, sample_file).decode('utf-8')\n",
    "    raw_file_path = os.path.join(raw_directory, sample_file).decode('utf-8')\n",
    "\n",
    "    # read pickle or raw dataset file with pandas\n",
    "    if os.path.isfile(pkl_file_path):\n",
    "        print(\"Sample File: \", pkl_file_path)\n",
    "        df = pd.read_pickle(pkl_file_path)\n",
    "    else:\n",
    "        print(\"Sample File: \", raw_file_path)\n",
    "        raw_df = pd.read_csv(raw_file_path, low_memory=False, dtype={'Label':'str'})\n",
    "        df = data_cleasing(raw_df)\n",
    "    \n",
    "    # data splitting\n",
    "    norm_train_df, cv_df, test_df, cv_label, test_label = data_splitting(df)\n",
    "    \n",
    "    # estimate the mean vector and the covariance matrix from the normal data\n",
    "    mu, sigma = estimateGaussian(norm_train_df)\n",
    "    \n",
    "    # estimate \n",
    "    p_cv = multivariateGaussian(cv_df, mu, sigma)    \n",
    "    p_test = multivariateGaussian(test_df, mu, sigma)\n",
    "    \n",
    "    # Cross Validation and threshold selection\n",
    "    fscore, epsilon = selectThresholdByCV(p_cv, cv_label)\n",
    "#     print('Best epsilon: ', epsilon)\n",
    "#     print('Best F1_score: ', fscore)\n",
    "    pred_cv_label = (p_cv < epsilon)\n",
    "    mgm_cv_label.extend(cv_label)\n",
    "    mgm_pred_cv_label.extend(pred_cv_label)\n",
    "    \n",
    "    # Test    \n",
    "    pred_test_label = (p_test < epsilon)    \n",
    "    mgm_test_label.extend(test_label)\n",
    "    mgm_pred_test_label.extend(pred_test_label)\n",
    "        \n",
    "    # Fit a Gaussian Mixture Model\n",
    "    # best_n_components, best_cov_type = model_order_selection(norm_train_df, len(norm_train_df.columns))\n",
    "    # gmm = mixture.GaussianMixture(n_components=best_n_components, covariance_type=best_cov_type)\n",
    "    gmm = mixture.GaussianMixture(n_components=10, covariance_type='full')\n",
    "    gmm.fit(norm_train_df)\n",
    "    \n",
    "    # Cross Validation and threshold selection\n",
    "    p_cv = gmm.score_samples(cv_df)\n",
    "    fscore, epsilon = selectThresholdByCV(p_cv, cv_label)\n",
    "#     print('Best epsilon: ', epsilon)\n",
    "#     print('Best F1_score: ', fscore)\n",
    "    pred_cv_label = (p_cv < epsilon)\n",
    "    gmm_cv_label.extend(cv_label)\n",
    "    gmm_pred_cv_label.extend(pred_cv_label)\n",
    "    \n",
    "    # Test\n",
    "    p_test = gmm.score_samples(test_df)\n",
    "    pred_label = (p_test < epsilon)\n",
    "    gmm_test_label.extend(test_label)\n",
    "    gmm_pred_test_label.extend(pred_test_label)\n",
    "   \n",
    "    \n",
    "print ('[MGM] Classification report for Cross Validation dataset')\n",
    "print_classification_report(mgm_cv_label, mgm_pred_cv_label)\n",
    "\n",
    "print ('[MGM] classification report for Test dataset')\n",
    "print_classification_report(mgm_test_label, mgm_pred_test_label)\n",
    "\n",
    "print ('[GMM] Classification report for Cross Validation dataset')\n",
    "print_classification_report(cv_label, pred_cv_label)\n",
    "\n",
    "print ('[GMM] Classification report for Test dataset')\n",
    "print_classification_report(test_label, pred_label)\n",
    "\n",
    "np.savetxt('mgm_cv_label.out', mgm_cv_label, delimiter=',')\n",
    "np.savetxt('mgm_pred_cv_label.out', mgm_pred_cv_label, delimiter=',')\n",
    "np.savetxt('mgm_test_label.out', mgm_test_label, delimiter=',')\n",
    "np.savetxt('mgm_pred_test_label.out', mgm_pred_test_label, delimiter=',')\n",
    "np.savetxt('gmm_cv_label.out', gmm_cv_label, delimiter=',')\n",
    "np.savetxt('gmm_pred_cv_label.out', gmm_pred_cv_label, delimiter=',')\n",
    "np.savetxt('gmm_test_label.out', gmm_test_label, delimiter=',')\n",
    "np.savetxt('gmm_pred_test_label.out', gmm_pred_test_label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nData Shape: \", df.shape)\n",
    "# print(\"\\nData Types: \", df.dtypes)\n",
    "# df.head()\n",
    "# data overview\n",
    "# print(\"\\nProto:\\n\", df['Proto'].value_counts())\n",
    "# print(\"\\nSrcAddr:\\n\", df['SrcAddr'].value_counts())\n",
    "# print(\"\\nDstAddr:\\n\", df['DstAddr'].value_counts())\n",
    "# print(\"\\nDport:\\n\", df['Dport'].value_counts())\n",
    "# print(\"\\nState:\\n\", df['State'].value_counts())\n",
    "# print(\"\\nsTos:\\n\", df['sTos'].value_counts())\n",
    "# print(\"\\ndTos:\\n\", df['dTos'].value_counts())\n",
    "# print(\"\\nLabel:\\n\", df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nData Shape: \", df.shape)\n",
    "# print(\"\\nData Types: \", df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# v_features = [\n",
    "#     'Dur',\n",
    "#     'Proto',\n",
    "#     'Dir',\n",
    "#     'Dport',\n",
    "#     'State',\n",
    "#     'TotPkts'\n",
    "# #     ,\n",
    "# #     'TotBytes',\n",
    "# #     'SrcBytes'\n",
    "# #     'SrcAddr0',\n",
    "# #     'DstAddr0',\n",
    "# #     'DstAddr1',\n",
    "# #     'DstAddr2',\n",
    "# #     'DstAddr3'\n",
    "# ]\n",
    "\n",
    "# nplots=np.size(v_features)\n",
    "# plt.figure(figsize=(15,4*nplots))\n",
    "# gs = gridspec.GridSpec(nplots,1)\n",
    "# for i, cn in enumerate(df[v_features]):\n",
    "#     ax = plt.subplot(gs[i])\n",
    "#     # print(cn)\n",
    "#     sns.distplot(df[cn][df.Label == 1], bins=10, label='anomaly', color='r')\n",
    "#     sns.distplot(df[cn][df.Label == 0], bins=10, label='normal', color='b')\n",
    "#     ax.set_xlabel('')\n",
    "#     ax.set_title('feature: ' + str(cn))\n",
    "#     plt.legend()\n",
    "# plt.savefig('distplot_df.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# corr = df.corr()\n",
    "# fig, ax = plt.subplots(figsize=(15,10))\n",
    "# sns_plot = sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, ax=ax)\n",
    "# figure = sns_plot.get_figure()\n",
    "# figure.savefig('figures/corr_df.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # drops N/A values\n",
    "# tmp_df = df.dropna()\n",
    "\n",
    "# # Create a scatter matrix of the aggregated dataframe\n",
    "# # choose a few interesting features to pairplot based on the heat maps\n",
    "# plot_features = ['Dur','Proto','Dir','Dport','State','sTos','dTos','TotPkts','Label']\n",
    "# sns_plot = sns.pairplot(tmp_df, vars=plot_features, hue='Label')\n",
    "# sns_plot.savefig(\"pairplot_df.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # The datastructure to hold our feature extraction functions, \n",
    "# # which will get applied to each aggregation of the datasets.\n",
    "# extractors = {\n",
    "#     'Label'   : [label_atk_v_norm, background_flow_count, normal_flow_count, n_conn,],\n",
    "#     'Dport'   : [n_dports_gt1024, n_dports_lt1024],\n",
    "#     'Sport'   : [n_sports_gt1024, n_sports_lt1024,],\n",
    "#     'Dur'     : [avg_duration,],\n",
    "#     'SrcAddr' : [n_s_a_p_address, n_s_b_p_address, n_s_c_p_address, n_s_na_p_address,],\n",
    "#     'DstAddr' : [n_d_a_p_address, n_d_b_p_address, n_d_c_p_address, n_d_na_p_address,],\n",
    "#     'Proto'   : [n_tcp, n_icmp, n_udp,],\n",
    "# }\n",
    "    \n",
    "# # resample grouped by 1 second bin. must have a datetime-like index.\n",
    "# r = df.resample('1S')\n",
    "# n_df = r.agg(extractors) ## aggretation by data and functions specified by extractors\n",
    "\n",
    "# n_df.columns = n_df.columns.droplevel(0) # get rid of the heirarchical columns\n",
    "# pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('New nData Types: ', n_df.dtypes)\n",
    "# n_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# n_features = ['background_flow_count','normal_flow_count','n_conn','n_dports>1024','n_dports<1024','n_s_a_p_address','n_s_b_p_address','n_s_c_p_address','n_s_na_p_address','n_d_a_p_address','n_d_b_p_address','n_d_c_p_address']\n",
    "# plt.figure(figsize=(15,4*nplots))\n",
    "# gs = gridspec.GridSpec(nplots,1)\n",
    "# for i, cn in enumerate(n_df[n_features]):\n",
    "#     ax = plt.subplot(gs[i])\n",
    "# #     print(cn)\n",
    "#     sns.distplot(n_df[cn][n_df.label == 1], bins=10, label='anomaly', color='r')\n",
    "#     sns.distplot(n_df[cn][n_df.label == 0], bins=10, label='normal', color='b')\n",
    "#     ax.set_xlabel('')\n",
    "#     ax.set_title('feature: ' + str(cn))\n",
    "#     plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# corr = n_df.corr()\n",
    "# fig, ax = plt.subplots(figsize=(15,10))\n",
    "# sns_plot = sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, ax=ax)\n",
    "# figure = sns_plot.get_figure()\n",
    "# figure.savefig('corr_df.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # drops N/A values\n",
    "# tmp_df = n_df.dropna()\n",
    "\n",
    "# # Create a scatter matrix of the aggregated dataframe\n",
    "# # choose a few interesting features to pairplot based on the heat maps\n",
    "# plot_features = ['avg_duration','n_udp','background_flow_count','n_conn','n_icmp']\n",
    "# sns.pairplot(tmp_df, vars=plot_features, hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # visualize p_cv \n",
    "# p_cv_df = pd.DataFrame(data={'Prob':p_cv,'Label':cv_label})\n",
    "# p_cv_df = p_cv_df.set_index(cv_df.index)\n",
    "# p_cv_df.head()\n",
    "\n",
    "# # plot distribution\n",
    "# plt.figure(figsize=(17,5))\n",
    "# sns.distplot(p_cv_df['Prob'][p_cv_df['Label'] == 1], bins=10, label='anomaly', color='r')\n",
    "# sns.distplot(p_cv_df['Prob'][p_cv_df['Label'] == 0], bins=10, label='normal', color='b')\n",
    "# plt.ylabel('Amount')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# # plot timeseries\n",
    "# plt.figure(figsize=(17,5))\n",
    "# anom_p_cv_df = p_cv_df[p_cv_df[\"Label\"] == 1]\n",
    "# norm_p_cv_df = p_cv_df[p_cv_df[\"Label\"] == 0]\n",
    "# anom_p_cv_df['Prob'].plot(style='g.', label='anomaly')\n",
    "# norm_p_cv_df['Prob'].plot(style='y.', label='normal')\n",
    "# plt.ylabel('Probability')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# # count probabilities\n",
    "# print(\"Anomalies:\\n\", anom_p_cv_df['Prob'].value_counts())\n",
    "# print(\"Normal:\\n\", norm_p_cv_df['Prob'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize p_test \n",
    "# p_test_df = pd.DataFrame(data={'Prob':p_test,'Label':test_label})\n",
    "# p_test_df = p_test_df.set_index(test_df.index)\n",
    "# p_test_df.head()\n",
    "\n",
    "# # plot distribution\n",
    "# plt.figure(figsize=(17,5))\n",
    "# sns.distplot(p_test_df['Prob'][p_test_df['Label'] == 1], bins=10, label='anomaly', color='r')\n",
    "# sns.distplot(p_test_df['Prob'][p_test_df['Label'] == 0], bins=10, label='normal', color='b')\n",
    "# plt.ylabel('Amount')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# # plot timeseries\n",
    "# plt.figure(figsize=(17,5))\n",
    "# anom_p_test_df = p_test_df[p_test_df[\"Label\"] == 1]\n",
    "# norm_p_test_df = p_test_df[p_test_df[\"Label\"] == 0]\n",
    "# norm_p_test_df['Prob'].plot(style='y.', label='normal')\n",
    "# anom_p_test_df['Prob'].plot(style='g.', label='anomaly')\n",
    "# plt.ylabel('Probability')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# # count probabilities\n",
    "# print(\"Anomalies:\\n\", anom_p_test_df['Prob'].value_counts())\n",
    "# print(\"Normal:\\n\", norm_p_test_df['Prob'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.version)\n",
    "\n",
    "# import matlab.engine\n",
    "# eng = matlab.engine.start_matlab()\n",
    "# print(eng.sqrt(4.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

%PORTUGUESE
\resumo{Resumo}{
Resumo em Português, espaçamento de 1.5 requerido pela norma (automático).
}
%ENGLISH
\vspace{2cm}
\resumo{Abstract}{

Signal processing techniques are usually applied for adaptive, streaming and real time problems, with high data volume and throughput. These techniques are widely adotped for denoising, signal separation and anomaly detection, and has attracted attention to apply signal processing for network attack detection. Recently, signal processing schemes have been applied to detect malicious traffic in computer networks, showing advances in network traffic analysis and network attack detection. Most of network-wide anomaly traffic detection methods are PCA-based method, which draw on PCA to divide traffic into normal and abnormal subspace, in accordance to anomaly detection problems.

Anomaly detection can be defined as the identification of rare and suspicious events by comparing they to the normal data. Anomalies are also referred to as outliers, novelties, noise or deviations, and can be related to network attacks, frauds or defects. Additionally, anomaly detection techniques can be categorized by classification, statistical algorithms, information theory and cluster based algorithms. Anomalies can be hard to identify and separate from normal data due to the rare occurrences of anomalies in comparison to normal events. Therefore anomaly detection algorithms have to be highly discriminating, robust to corruption and able to deal with the imbalanced data problem.

As a first important contribution, we propose the Eigensimilarity, which is an approach based on signal processing concepts applied to detection of malicious traffic in computer networks. Eigensimilarity models the network traffic using a signal processing formulation as a composition of three components: signal, artifact and noise, taking into account the incoming and outgoing traffic in certain types of network ports (TCP or UDP). The Eigensimilarity is based on eigenvalue analysis, model order selection (MOS) and similarity analysis between eigenvectors, where MOS and eigenvalue analysis are applied to detect time frames under attack, while the similarity analysis between eigenvectors aims the detection of the exxact time and network ports under attack. We evaluate the accuracy and performance of the proposed framework applied to a simulated scenario and to the DARPA 1998 data set. The performed experiments show that synflood, fraggle and port scan attacks can be detected accurately by Eigensimilarity and with great detail in an automatic and blind fashion, i.e. in an unsupervised approach.

The high availability of raw data increases the challenges related to big data analytics and to imbalanced learning problems, which corresponds to data sets exhibiting significant imbalances of classes or rare events of some classes. The fundamental issue with the imbalanced learning is the ability of imbalanced data to significantly compromise the performance of most standard learning algorithms. Data analysis of imbalanced data is challenging for classification and prediction problems related to anomaly detection, novelty detection, fraud detection and attack detection... link to fraud and skewed data

Some widely adopted algorithms for anomaly detection assume a gaussian distributed data, however this assumption may not be observed in real world problems, such as the case of network traffic analysis, where network traffic features are usually more characterized by skewed and heavy-tailed distributions. Findings indicate that certain positive skewed and heavy-tailed distributions can model data center switch traffic, and highlights a difference between the data center environment and the wide area network. These findings show that the skewness and heavy-tailed distributions may be important for network traffic analysis, and can motivate researches to evaluate the impact of skewed data into algorithms that rely on Gaussian distributed data. 

We believe that the skewness of anomalous and normal traffic can highlight features for improving anomaly detection in imbalanced data, and that the distance between robust estimates of normal traffic and contaminated observations can highlight discrepancies and be used for network attack detection. Therefore, we propose the m-RPCA, which is an approach based on distances between moments computed from a robust subspace learned by Robust Principal Component Analysis (RPCA) and contaminated observations, in order to detect anomalies from skewed data and network traffic. The anomaly detection from contaminated observations evaluate the Mahalanobis distance between the robust moments and new contaminated observations, in a semi-supervised fashion, but m-RPCA can also be computed as an unsupervised algorithm, with subspace learning from the contaminated data. 

We evaluate the accuracy of the m-RPCA for anomaly detection on simulated data sets, with skewed and heavy-tailed distributions, and for the CTU-13 data set. The Experimental evaluation compares our proposal to widely adopted algorithms for anomaly detection based on clustering and statistical approaches, and shows that the distance between robust estimates and contaminated observations can improve the anomaly detection on skewed data and the m-RPCA can be adoted for network attack detection.

Moreover, we propose an architecture and approach to evaluate a prove of concept of Eigensimilarity for malicious behavior detection, in order to detect possible threats in offline corporate mobile applications. We propose scenarios, features and approaches for threats by means of Eigensimilarity, and evaluate the processing time required for Eigensimilarity execution in mobile devices.

}
